[
    {
        "             Statistical mechanics is one of the pillars of modern ": null
    },
    {
        "physics": "physics"
    },
    {
        ". It is necessary for the fundamental study of any physical system that has many ": null
    },
    {
        "degrees of freedom": "degrees of freedom"
    },
    {
        ". The approach is based on ": null
    },
    {
        "statistical": "statistics"
    },
    {
        " methods, ": null
    },
    {
        "probability theory": "probability theory"
    },
    {
        " and the ": null
    },
    {
        "microscopic": "microscopic scale"
    },
    {
        " physical laws.      It can be used to explain the ": null
    },
    {
        "thermodynamic": "thermodynamics"
    },
    {
        " behaviour of large systems. This branch of statistical mechanics, which treats and extends classical thermodynamics, is known as statistical thermodynamics or equilibrium statistical mechanics.     Statistical mechanics shows how the concepts from macroscopic observations are related to the description of microscopic state that fluctuates around an average state. It connects thermodynamic quantities  to microscopic behavior, whereas, in ": null
    },
    {
        "classical thermodynamics": "classical thermodynamics"
    },
    {
        ", the only available option would be to measure and tabulate such quantities for various materials.     Statistical mechanics can also be used to study systems that are out of equilibrium. An important subbranch known as non-equilibrium statistical mechanics  deals with the issue of microscopically modelling the speed of ": null
    },
    {
        "irreversible process": "irreversible process"
    },
    {
        "es that are driven by imbalances. Examples of such processes include chemical reactions or flows of particles and heat. The ": null
    },
    {
        "fluctuation–dissipation theorem": "fluctuation–dissipation theorem"
    },
    {
        " is the basic knowledge obtained from applying ": null
    },
    {
        "non-equilibrium statistical mechanics": "non-equilibrium statistical mechanics"
    },
    {
        " to study the simplest non-equilibrium situation of a steady state current flow in a system of many particles.            In physics, there are two types of mechanics usually examined: ": null
    },
    {
        "classical mechanics": "classical mechanics"
    },
    {
        " and ": null
    },
    {
        "quantum mechanics": "quantum mechanics"
    },
    {
        ". For both types of mechanics, the standard mathematical approach is to consider two concepts:   The complete state of the mechanical system at a given time, mathematically encoded as a ": null
    },
    {
        "phase point": "phase space"
    },
    {
        " or a pure ": null
    },
    {
        "quantum state vector": "quantum state vector"
    },
    {
        " .   An equation of motion which carries the state forward in time: ": null
    },
    {
        "Hamiltons equations": "hamiltons equations"
    },
    {
        " or the ": null
    },
    {
        "time-dependent Schrödinger equation": "time-dependent schrödinger equation"
    },
    {
        "   Using these two concepts, the state at any other time, past or future, can in principle be calculated.   There is however a disconnection between these laws and everyday life experiences, as we do not find it necessary to know exactly at a microscopic level the simultaneous positions and velocities of each molecule while carrying out processes at the human scale . Statistical mechanics fills this disconnection between the laws of mechanics and the practical experience of incomplete knowledge, by adding some uncertainty about which state the system is in.     Whereas ordinary mechanics only considers the behaviour of a single state, statistical mechanics introduces the ": null
    },
    {
        "statistical ensemble": "statistical ensemble"
    },
    {
        ", which is a large collection of virtual, independent copies of the system in various states. The statistical ensemble is a ": null
    },
    {
        "probability distribution": "probability distribution"
    },
    {
        " over all possible states of the system. In classical statistical mechanics, the ensemble is a probability distribution over phase points , usually represented as a distribution in a ": null
    },
    {
        "phase space": "phase space"
    },
    {
        " with ": null
    },
    {
        "canonical coordinates": "canonical coordinates"
    },
    {
        ". In quantum statistical mechanics, the ensemble is a probability distribution over pure states, and can be compactly summarized as a ": null
    },
    {
        "density matrix": "density matrix"
    },
    {
        ".     As is usual for probabilities, the ensemble can be interpreted in different ways:   an ensemble can be taken to represent the various possible states that a single system could be in , or   the members of the ensemble can be understood as the states of the systems in experiments repeated on independent systems which have been prepared in a similar but imperfectly controlled manner , in the limit of an infinite number of trials.   These two meanings are equivalent for many purposes, and will be used interchangeably in this article.     However the probability is interpreted, each state in the ensemble evolves over time according to the equation of motion. Thus, the ensemble itself also evolves, as the virtual systems in the ensemble continually leave one state and enter another. The ensemble evolution is given by the ": null
    },
    {
        "Liouville equation": "liouvilles theorem"
    },
    {
        " or the ": null
    },
    {
        "von Neumann equation": "von neumann equation"
    },
    {
        " . These equations are simply derived by the application of the mechanical equation of motion separately to each virtual system contained in the ensemble, with the probability of the virtual system being conserved over time as it evolves from state to state.     One special class of ensemble is those ensembles that do not evolve over time. These ensembles are known as equilibrium ensembles and their condition is known as statistical equilibrium. Statistical equilibrium occurs if, for each state in the ensemble, the ensemble also contains all of its future and past states with probabilities equal to the probability of being in that state. The study of equilibrium ensembles of isolated systems is the focus of statistical thermodynamics. Non-equilibrium statistical mechanics addresses the more general case of ensembles that change over time, and/or ensembles of non-isolated systems.       The primary goal of statistical thermodynamics is to derive the ": null
    },
    {
        "classical thermodynamics": "classical thermodynamics"
    },
    {
        " of materials in terms of the properties of their constituent particles and the interactions between them. In other words, statistical thermodynamics provides a connection between the macroscopic properties of materials in ": null
    },
    {
        "thermodynamic equilibrium": "thermodynamic equilibrium"
    },
    {
        ", and the microscopic behaviours and motions occurring inside the material.     Whereas statistical mechanics proper involves dynamics, here the attention is focussed on statistical equilibrium . Statistical equilibrium does not mean that the particles have stopped moving , rather, only that the ensemble is not evolving.       A ": null
    },
    {
        "sufficient": "sufficient condition"
    },
    {
        " condition for statistical equilibrium with an isolated system is that the probability distribution is a function only of conserved properties .   There are many different equilibrium ensembles that can be considered, and only some of them correspond to thermodynamics. Additional postulates are necessary to motivate why the ensemble for a given system should have one form or another.     A common approach found in many textbooks is to take the equal a priori probability postulate. This postulate states that   : For an isolated system with an exactly known energy and exactly known composition, the system can be found with equal probability in any microstate consistent with that knowledge.   The equal a priori probability postulate therefore provides a motivation for the ": null
    },
    {
        "microcanonical ensemble": "microcanonical ensemble"
    },
    {
        " described below. There are various arguments in favour of the equal a priori probability postulate:   ": null
    },
    {
        "Ergodic hypothesis": "ergodic hypothesis"
    },
    {
        ": An ergodic system is one that evolves over time to explore all accessible states: all those with the same energy and composition. In an ergodic system, the microcanonical ensemble is the only possible equilibrium ensemble with fixed energy. This approach has limited applicability, since most systems are not ergodic.   ": null
    },
    {
        "Principle of indifference": "principle of indifference"
    },
    {
        ": In the absence of any further information, we can only assign equal probabilities to each compatible situation.   ": null
    },
    {
        "Maximum information entropy": "maximum entropy thermodynamics"
    },
    {
        ": A more elaborate version of the principle of indifference states that the correct ensemble is the ensemble that is compatible with the known information and that has the largest ": null
    },
    {
        "Gibbs entropy": "gibbs entropy"
    },
    {
        " .    Other fundamental postulates for statistical mechanics have also been proposed.            There are three equilibrium ensembles with a simple form that can be defined for any ": null
    },
    {
        "isolated system": "isolated system"
    },
    {
        " bounded inside a finite volume. These are the most often discussed ensembles in statistical thermodynamics. In the macroscopic limit they all correspond to classical thermodynamics.   ; ": null
    },
    {
        "Microcanonical ensemble": "microcanonical ensemble"
    },
    {
        "   : describes a system with a precisely given energy and fixed composition . The microcanonical ensemble contains with equal probability each possible state that is consistent with that energy and composition.   ; ": null
    },
    {
        "Canonical ensemble": "canonical ensemble"
    },
    {
        "   : describes a system of fixed composition that is in ": null
    },
    {
        "thermal equilibrium": "thermal equilibrium"
    },
    {
        " with a ": null
    },
    {
        "heat bath": "heat bath"
    },
    {
        " of a precise ": null
    },
    {
        "temperature": "thermodynamic temperature"
    },
    {
        ". The canonical ensemble contains states of varying energy but identical composition; the different states in the ensemble are accorded different probabilities depending on their total energy.   ; ": null
    },
    {
        "Grand canonical ensemble": "grand canonical ensemble"
    },
    {
        "   : describes a system with non-fixed composition that is in thermal and chemical equilibrium with a thermodynamic reservoir. The reservoir has a precise temperature, and precise ": null
    },
    {
        "chemical potentials": "chemical potential"
    },
    {
        "for various types of particle. The grand canonical ensemble contains states of varying energy and varying numbers of particles; the different states in the ensemble are accorded different probabilities depending on their total energy and total particle numbers.     For systems containing many particles , all three of the ensembles listed above tend to give identical behaviour. It is then simply a matter of mathematical convenience which ensemble is used.  The Gibbs theorem about equivalence of ensembles  was developed into the theory of ": null
    },
    {
        "concentration of measure": "concentration of measure"
    },
    {
        " phenomenon, . which has applications in many areas of science, from functional analysis to methods of ": null
    },
    {
        "artificial intelligence": "artificial intelligence"
    },
    {
        " and ": null
    },
    {
        "big data": "big data"
    },
    {
        " technology.      Important cases where the thermodynamic ensembles do not give identical results include:   Microscopic systems.   Large systems at a phase transition.   Large systems with long-range interactions.   In these cases the correct thermodynamic ensemble must be chosen as there are observable differences between these ensembles not just in the size of fluctuations, but also in average quantities such as the distribution of particles. The correct ensemble is that which corresponds to the way the system has been prepared and characterized—in other words, the ensemble that reflects the knowledge about that system.     :       Once the characteristic state function for an ensemble has been calculated for a given system, that system is solved . Calculating the characteristic state function of a thermodynamic ensemble is not necessarily a simple task, however, since it involves considering every possible state of the system. While some hypothetical systems have been exactly solved, the most general case is too complex for an exact solution. Various approaches exist to approximate the true ensemble and allow calculation of average quantities.         There are some cases which allow exact solutions.     For very small microscopic systems, the ensembles can be directly computed by simply enumerating over all possible states of the system .   Some large systems consist of many separable microscopic systems, and each of the subsystems can be analysed independently. Notably, idealized gases of non-interacting particles have this property, allowing exact derivations of ": null
    },
    {
        "Maxwell–Boltzmann statistics": "maxwell–boltzmann statistics"
    },
    {
        ", ": null
    },
    {
        "Fermi–Dirac statistics": "fermi–dirac statistics"
    },
    {
        ", and ": null
    },
    {
        "Bose–Einstein statistics": "bose–einstein statistics"
    },
    {
        ".   A few large systems with interaction have been solved. By the use of subtle mathematical techniques, exact solutions have been found for a few ": null
    },
    {
        "toy model": "toy model"
    },
    {
        "s.  Some examples include the ": null
    },
    {
        "Bethe ansatz": "bethe ansatz"
    },
    {
        ", ": null
    },
    {
        "square-lattice Ising model": "square-lattice ising model"
    },
    {
        " in zero field, ": null
    },
    {
        "hard hexagon model": "hard hexagon model"
    },
    {
        ".            One approximate approach that is particularly well suited to computers is the ": null
    },
    {
        "Monte Carlo method": "monte carlo method"
    },
    {
        ", which examines just a few of the possible states of the system, with the states chosen randomly . As long as these states form a representative sample of the whole set of states of the system, the approximate characteristic function is obtained. As more and more random samples are included, the errors are reduced to an arbitrarily low level.     The ": null
    },
    {
        "Metropolis–Hastings algorithm": "metropolis–hastings algorithm"
    },
    {
        " is a classic Monte Carlo method which was initially used to sample the canonical ensemble.   ": null
    },
    {
        "Path integral Monte Carlo": "path integral monte carlo"
    },
    {
        ", also used to sample the canonical ensemble.       For rarefied non-ideal gases, approaches such as the ": null
    },
    {
        "cluster expansion": "cluster expansion"
    },
    {
        " use ": null
    },
    {
        "perturbation theory": "perturbation theory"
    },
    {
        " to include the effect of weak interactions, leading to a ": null
    },
    {
        "virial expansion": "virial expansion"
    },
    {
        ".   For dense fluids, another approximate approach is based on reduced distribution functions, in particular the ": null
    },
    {
        "radial distribution function": "radial distribution function"
    },
    {
        ".   ": null
    },
    {
        "Molecular dynamics": "molecular dynamics"
    },
    {
        " computer simulations can be used to calculate ": null
    },
    {
        "microcanonical ensemble": "microcanonical ensemble"
    },
    {
        " averages, in ergodic systems. With the inclusion of a connection to a stochastic heat bath, they can also model canonical and grand canonical conditions.   Mixed methods involving non-equilibrium statistical mechanical results may be useful.            There are many physical phenomena of interest that involve quasi-thermodynamic processes out of equilibrium, for example:   ": null
    },
    {
        "heat transport by the internal motions in a material": "thermal conduction"
    },
    {
        ", driven by a temperature imbalance,   ": null
    },
    {
        "electric currents carried by the motion of charges in a conductor": "electrical conduction"
    },
    {
        ", driven by a voltage imbalance,   spontaneous ": null
    },
    {
        "chemical reactions": "chemical reaction"
    },
    {
        "driven by a decrease in free energy,   ": null
    },
    {
        "friction": "friction"
    },
    {
        ", ": null
    },
    {
        "dissipation": "dissipation"
    },
    {
        ", ": null
    },
    {
        "quantum decoherence": "quantum decoherence"
    },
    {
        ",   systems being pumped by external forces ,   and irreversible processes in general.   All of these processes occur over time with characteristic rates, and these rates are of importance for engineering. The field of non-equilibrium statistical mechanics is concerned with understanding these non-equilibrium processes at the microscopic level.     In principle, non-equilibrium statistical mechanics could be mathematically exact: ensembles for an isolated system evolve over time according to deterministic equations such as ": null
    },
    {
        "Liouvilles equation": "liouvilles theorem"
    },
    {
        " or its quantum equivalent, the ": null
    },
    {
        "von Neumann equation": "von neumann equation"
    },
    {
        ". These equations are the result of applying the mechanical equations of motion independently to each state in the ensemble. Unfortunately, these ensemble evolution equations inherit much of the complexity of the underlying mechanical motion, and so exact solutions are very difficult to obtain. Moreover, the ensemble evolution equations are fully reversible and do not destroy information . In order to make headway in modelling irreversible processes, it is necessary to consider additional factors besides probability and reversible mechanics.     Non-equilibrium mechanics is therefore an active area of theoretical research as the range of validity of these additional assumptions continues to be explored. A few approaches are described in the following subsections.       One approach to non-equilibrium statistical mechanics is to incorporate ": null
    },
    {
        "stochastic": "stochastic"
    },
    {
        " behaviour into the system. Stochastic behaviour destroys information contained in the ensemble. While this is technically inaccurate , the randomness is added to reflect that information of interest becomes converted over time into subtle correlations within the system, or to correlations between the system and environment. These correlations appear as ": null
    },
    {
        "chaotic": "chaos theory"
    },
    {
        " or ": null
    },
    {
        "pseudorandom": "pseudorandom"
    },
    {
        " influences on the variables of interest. By replacing these correlations with randomness proper, the calculations can be made much easier.            Another important class of non-equilibrium statistical mechanical models deals with systems that are only very slightly perturbed from equilibrium. With very small perturbations, the response can be analysed in ": null
    },
    {
        "linear response theory": "linear response theory"
    },
    {
        ". A remarkable result, as formalized by the ": null
    },
    {
        "fluctuation-dissipation theorem": "fluctuation-dissipation theorem"
    },
    {
        ", is that the response of a system when near equilibrium is precisely related to the ": null
    },
    {
        "fluctuations": "statistical fluctuations"
    },
    {
        " that occur when the system is in total equilibrium. Essentially, a system that is slightly away from equilibrium—whether put there by external forces or by fluctuations—relaxes towards equilibrium in the same way, since the system cannot tell the difference or know how it came to be away from equilibrium.      This provides an indirect avenue for obtaining numbers such as ": null
    },
    {
        "ohmic conductivity": "ohms law"
    },
    {
        " and ": null
    },
    {
        "thermal conductivity": "thermal conductivity"
    },
    {
        " by extracting results from equilibrium statistical mechanics. Since equilibrium statistical mechanics is mathematically well defined and more amenable for calculations, the fluctuation-dissipation connection can be a convenient shortcut for calculations in near-equilibrium statistical mechanics.     A few of the theoretical tools used to make this connection include:   ": null
    },
    {
        "Fluctuation–dissipation theorem": "fluctuation–dissipation theorem"
    },
    {
        " Onsager reciprocal relations": "onsager reciprocal relations"
    },
    {
        " Green–Kubo relations": "green–kubo relations"
    },
    {
        " Landauer–Büttiker formalism": "ballistic conductionlandauer-büttiker formalism"
    },
    {
        " Mori–Zwanzig formalism": "mori–zwanzig formalism"
    },
    {
        "       An advanced approach uses a combination of stochastic methods and linear response theory. As an example, one approach to compute quantum coherence effects  in the conductance of an electronic system is the use of the Green-Kubo relations, with the inclusion of stochastic ": null
    },
    {
        "dephasing": "dephasing"
    },
    {
        " by interactions between various electrons by use of the Keldysh method.         The ensemble formalism also can be used to analyze general mechanical systems with uncertainty in knowledge about the state of a system. Ensembles are also used in:   ": null
    },
    {
        "propagation of uncertainty": "propagation of uncertainty"
    },
    {
        " over time,   ": null
    },
    {
        "regression analysis": "regression analysis"
    },
    {
        " of gravitational ": null
    },
    {
        "orbit": "orbit"
    },
    {
        "s,   ": null
    },
    {
        "ensemble forecasting": "ensemble forecasting"
    },
    {
        " of weather,   dynamics of ": null
    },
    {
        "neural networks": "neural networks"
    },
    {
        ",   bounded-rational ": null
    },
    {
        "potential games": "potential game"
    },
    {
        "in game theory and economics.       In 1738, Swiss physicist and mathematician ": null
    },
    {
        "Daniel Bernoulli": "daniel bernoulli"
    },
    {
        " published Hydrodynamica which laid the basis for the ": null
    },
    {
        "kinetic theory of gases": "kinetic theory of gases"
    },
    {
        ". In this work, Bernoulli posited the argument, still used to this day, that gases consist of great numbers of molecules moving in all directions, that their impact on a surface causes the gas pressure that we feel, and that what we experience as ": null
    },
    {
        "heat": "heat"
    },
    {
        " is simply the kinetic energy of their motion.     In 1859, after reading a paper on the diffusion of molecules by ": null
    },
    {
        "Rudolf Clausius": "rudolf clausius"
    },
    {
        ", Scottish physicist ": null
    },
    {
        "James Clerk Maxwell": "james clerk maxwell"
    },
    {
        " formulated the ": null
    },
    {
        "Maxwell distribution": "maxwell distribution"
    },
    {
        " of molecular velocities, which gave the proportion of molecules having a certain velocity in a specific range. See:   Maxwell, J.C.  Philosophical Magazine, 4th series, 19 : 19–32.   Maxwell, J.C.  Philosophical Magazine, 4th series, 20 : 21–37. This was the first-ever statistical law in physics.  Maxwell also gave the first mechanical argument that molecular collisions entail an equalization of temperatures and hence a tendency towards equilibrium.  Five years later, in 1864, ": null
    },
    {
        "Ludwig Boltzmann": "ludwig boltzmann"
    },
    {
        ", a young student in Vienna, came across Maxwells paper and spent much of his life developing the subject further.     Statistical mechanics proper was initiated in the 1870s with the work of Boltzmann, much of which was collectively published in his 1896 Lectures on Gas Theory.  Boltzmanns original papers on the statistical interpretation of thermodynamics, the ": null
    },
    {
        "H-theorem": "h-theorem"
    },
    {
        ", ": null
    },
    {
        "transport theory": "transport theory"
    },
    {
        ", ": null
    },
    {
        "thermal equilibrium": "thermal equilibrium"
    },
    {
        ", the ": null
    },
    {
        "equation of state": "equation of state"
    },
    {
        " of gases, and similar subjects, occupy about 2,000 pages in the proceedings of the Vienna Academy and other societies. Boltzmann introduced the concept of an equilibrium statistical ensemble and also investigated for the first time non-equilibrium statistical mechanics, with his ": null
    },
    {
        "H-theorem": "h-theorem"
    },
    {
        ".     The term statistical mechanics was coined by the American mathematical physicist ": null
    },
    {
        "J. Willard Gibbs": "josiah willard gibbs"
    },
    {
        " in 1884. J. W. Gibbs, On the Fundamental Formula of Statistical Mechanics, with Applications to Astronomy and Thermodynamics. Proceedings of the American Association for the Advancement of Science, 33, 57-58 . Reproduced in The Scientific Papers of J. Willard Gibbs, Vol II , .  Probabilistic mechanics might today seem a more appropriate term, but statistical mechanics is firmly entrenched.  Shortly before his death, Gibbs published in 1902  Elementary Principles in Statistical Mechanics , a book which formalized statistical mechanics as a fully general approach to address all mechanical systems—macroscopic or microscopic, gaseous or non-gaseous. Gibbs methods were initially derived in the framework ": null
    },
    {
        "classical mechanics": "classical mechanics"
    },
    {
        ", however they were of such generality that they were found to adapt easily to the later ": null
    },
    {
        "quantum mechanics": "quantum mechanics"
    }
]