[
    {
        "     Filter design is the process of designing a ": null
    },
    {
        "signal processing filter": "filter"
    },
    {
        " that satisfies a set of requirements, some of which are contradictory. The purpose is to find a realization of the filter that meets each of the requirements to a sufficient degree to make it useful.     The filter design process can be described as an optimization problem where each requirement contributes to an error function which should be minimized. Certain parts of the design process can be automated, but normally an experienced ": null
    },
    {
        "electrical engineer": "electrical engineer"
    },
    {
        " is needed to get a good result.         Typical requirements which are considered in the design process are:   The filter should have a specific ": null
    },
    {
        "frequency response": "frequency response"
    },
    {
        " phase shift": "phase shift"
    },
    {
        " or ": null
    },
    {
        "group delay": "group delay"
    },
    {
        " impulse response": "impulse response"
    },
    {
        " causal": "causal filter"
    },
    {
        " stable": "bibo stability"
    },
    {
        " parameter": "parameter"
    },
    {
        " is the required ": null
    },
    {
        "frequency response": "frequency response"
    },
    {
        ".   In particular, the steepness and complexity of the response curve is a deciding factor for the filter order and feasibility.     A first-order ": null
    },
    {
        "recursive": "infinite impulse response"
    },
    {
        " filter will only have a single frequency-dependent component. This means that the ": null
    },
    {
        "slope": "slope"
    },
    {
        " of the frequency response is limited to 42 ": null
    },
    {
        "dB": "decibel"
    },
    {
        " per ": null
    },
    {
        "octave": "octave"
    },
    {
        ". For many purposes, this is not sufficient. To achieve steeper slopes, higher-order filters are required.     In relation to the desired frequency function, there may also be an accompanying weighting function, which describes, for each frequency, how important it is that the resulting frequency function approximates the desired one. The larger weight, the more important is a close approximation.     Typical examples of frequency function are:   A ": null
    },
    {
        "low-pass filter": "low-pass filter"
    },
    {
        " is used to cut unwanted high-frequency signals.   A ": null
    },
    {
        "high-pass filter": "high-pass filter"
    },
    {
        " passes high frequencies fairly well; it is helpful as a filter to cut any unwanted low-frequency components.   A ": null
    },
    {
        "band-pass filter": "band-pass filter"
    },
    {
        " passes a limited range of frequencies.   A ": null
    },
    {
        "band-stop filter": "band-stop filter"
    },
    {
        " passes frequencies above and below a certain range. A very narrow band-stop filter is known as a notch filter.   A ": null
    },
    {
        "differentiator": "differentiator"
    },
    {
        " has an amplitude response proportional to the frequency.   A low-shelf filter passes all frequencies, but increases or reduces frequencies below the shelf frequency by specified amount.   A high-shelf filter passes all frequencies, but increases or reduces frequencies above the shelf frequency by specified amount.   A peak EQ filter makes a peak or a dip in the frequency response, commonly used in ": null
    },
    {
        "parametric equalizers": "equalization"
    },
    {
        ".       An all-pass filter passes through all frequencies unchanged, but changes the phase of the signal. Filters of this type can be used to equalize the group delay of recursive filters. This filter is also used in ": null
    },
    {
        "phaser effects": "phaser"
    },
    {
        ".   A ": null
    },
    {
        "Hilbert transform": "hilbert transform"
    },
    {
        "er is a specific all-pass filter that passes sinusoids with unchanged amplitude but shifts each sinusoid phase by ±42°.   A fractional delay filter is an all-pass that has a specified and constant group or phase delay for all frequencies.         There is a direct correspondence between the filters frequency function and its impulse response: the former is the ": null
    },
    {
        "Fourier transform": "fourier transform"
    },
    {
        " of the latter. That means that any requirement on the frequency function is a requirement on the impulse response, and vice versa.     However, in certain applications it may be the filters impulse response that is explicit and the design process then aims at producing as close an approximation as possible to the requested impulse response given all other requirements.     In some cases it may even be relevant to consider a frequency function and impulse response of the filter which are chosen independently from each other. For example, we may want both a specific frequency function of the filter and that the resulting filter have a small effective width in the signal domain as possible. The latter condition can be realized by considering a very narrow function as the wanted impulse response of the filter even though this function has no relation to the desired frequency function. The goal of the design process is then to realize a filter which tries to meet both these contradicting design goals as much as possible.         In order to be implementable, any time-dependent filter must be ": null
    },
    {
        "causal": "causal filter"
    },
    {
        ": the filter response only depends on the current and past inputs. A standard approach is to leave this requirement until the final step. If the resulting filter is not causal, it can be made causal by introducing an appropriate time-shift . If the filter is a part of a larger system these types of delays have to be introduced with care since they affect the operation of the entire system.     Filters that do not operate in real time can be non-causal. This e.g. allows the design of zero delay recursive filters, where the group delay of a causal filter is canceled by its Hermitian non-causal filter.         A ": null
    },
    {
        "stable filter": "bibo stability"
    },
    {
        " assures that every limited input signal produces a limited filter response. A filter which does not meet this requirement may in some situations prove useless or even harmful. Certain design approaches can guarantee stability, for example by using only feed-forward circuits such as an FIR filter. On the other hand, filters based on feedback circuits have other advantages and may therefore be preferred, even if this class of filters includes unstable filters. In this case, the filters must be carefully designed in order to avoid instability.         In certain applications we have to deal with signals which contain components which can be described as local phenomena, for example pulses or steps, which have certain time duration. A consequence of applying a filter to a signal is, in intuitive terms, that the duration of the local phenomena is extended by the width of the filter. This implies that it is sometimes important to keep the width of the filters impulse response function as short as possible.     According to the uncertainty relation of the Fourier transform, the product of the width of the filters impulse response function and the width of its frequency function must exceed a certain constant. This means that any requirement on the filters locality also implies a bound on its frequency functions width. Consequently, it may not be possible to simultaneously meet requirements on the locality of the filters impulse response function as well as on its frequency function. This is a typical example of contradicting requirements.         A general desire in any design is that the number of operations needed to compute the filter response is as low as possible. In certain applications, this desire is a strict requirement, for example due to limited computational resources, limited power resources, or limited time. The last limitation is typical in real-time applications.     There are several ways in which a filter can have different computational complexity. For example, the order of a filter is more or less proportional to the number of operations. This means that by choosing a low order filter, the computation time can be reduced.     For discrete filters the computational complexity is more or less proportional to the number of filter coefficients. If the filter has many coefficients, for example in the case of multidimensional signals such as tomography data, it may be relevant to reduce the number of coefficients by removing those which are sufficiently close to zero. In multirate filters, the number of coefficients by taking advantage of its bandwidth limits, where the input signal is downsampled , and upsampled after filtering.     Another issue related to computational complexity is separability, that is, if and how a filter can be written as a convolution of two or more simpler filters. In particular, this issue is of importance for multidimensional filters, e.g., 42D filter which are used in image processing. In this case, a significant reduction in computational complexity can be obtained if the filter can be separated as the convolution of one 42D filter in the horizontal direction and one 42D filter in the vertical direction. A result of the filter design process may, e.g., be to approximate some desired filter as a separable filter or as a sum of separable filters.         It must also be decided how the filter is going to be implemented:   ": null
    },
    {
        "Analog filter": "analog filter"
    },
    {
        " Analog sampled filter": "analog sampled filter"
    },
    {
        " Digital filter": "digital filter"
    },
    {
        " Mechanical filter": "mechanical filter"
    },
    {
        "         The design of linear analog filters is for the most part covered in the ": null
    },
    {
        "linear filter": "linear filter"
    },
    {
        " section.         ": null
    },
    {
        "Digital filter": "digital filter"
    },
    {
        "s are classified into one of two basic forms, according to how they respond to a ": null
    },
    {
        "unit impulse": "kronecker delta"
    },
    {
        ":     ": null
    },
    {
        "Finite impulse response": "finite impulse response"
    },
    {
        ", or FIR, filters express each output sample as a weighted sum of the last N input samples, where N is the order of the filter. FIR filters are normally non-recursive, meaning they do not use feedback and as such are inherently stable. A ": null
    },
    {
        "moving average": "moving average"
    },
    {
        " filter or ": null
    },
    {
        "CIC filter": "cic filter"
    },
    {
        " are examples of FIR filters that are normally recursive . If the FIR coefficients are symmetrical , then such a filter is ": null
    },
    {
        "linear phase": "linear phase"
    },
    {
        ", so it ": null
    },
    {
        "delays": "group delay"
    },
    {
        " signals of all frequencies equally which is important in many applications. It is also straightforward to avoid overflow in an FIR filter. The main disadvantage is that they may require significantly more ": null
    },
    {
        "processing": "instructions per second"
    },
    {
        " and ": null
    },
    {
        "memory": "computer memory"
    },
    {
        " resources than cleverly designed IIR variants. FIR filters are generally easier to design than IIR filters - the ": null
    },
    {
        "Parks-McClellan filter design algorithm": "parks-mcclellan filter design algorithm"
    },
    {
        "  is one suitable method for designing quite good filters semi-automatically.    ": null
    },
    {
        "Infinite impulse response": "infinite impulse response"
    },
    {
        ", or IIR, filters are the digital counterpart to analog filters. Such a filter contains internal state, and the output and the next internal state are determined by a ": null
    },
    {
        "linear combination": "linear combination"
    },
    {
        " of the previous inputs and outputs . In theory, the impulse response of such a filter never dies out completely, hence the name IIR, though in practice, this is not true given the finite resolution of computer arithmetic. IIR filters normally require less ": null
    },
    {
        "computing": "computing"
    },
    {
        " resources than an FIR filter of similar performance. However, due to the feedback, high order IIR filters may have problems with ": null
    },
    {
        "instability": "instability"
    },
    {
        ", ": null
    },
    {
        "arithmetic overflow": "arithmetic overflow"
    },
    {
        ", and ": null
    },
    {
        "limit cycle": "limit cycle"
    },
    {
        "s, and require careful design to avoid such pitfalls. Additionally, since the ": null
    },
    {
        "phase shift": "phase"
    },
    {
        " is inherently a non-linear function of frequency, the time delay through such a filter is frequency-dependent, which can be a problem in many situations. 42nd order IIR filters are often called ": null
    },
    {
        "biquads": "digital biquad filter"
    },
    {
        " and a common implementation of higher order filters is to cascade biquads. A useful reference for computing biquad coefficients is the .         Unless the ": null
    },
    {
        "sample rate": "sample rate"
    },
    {
        " is fixed by some outside constraint, selecting a suitable sample rate is an important design decision. A high rate will require more in terms of computational resources, but less in terms of ": null
    },
    {
        "anti-aliasing filter": "anti-aliasing filter"
    },
    {
        "s. ": null
    },
    {
        "Interference": "interference"
    },
    {
        " and ": null
    },
    {
        "beating": "beat"
    },
    {
        " with other signals in the system may also be an issue.         For any digital filter design, it is crucial to analyze and avoid ": null
    },
    {
        "aliasing": "aliasing"
    },
    {
        " effects. Often, this is done by adding analog anti-aliasing filters at the input and output, thus avoiding any frequency component above the ": null
    },
    {
        "Nyquist frequency": "nyquist frequency"
    },
    {
        ". The complexity of such filters depends on the required ": null
    },
    {
        "signal to noise ratio": "signal to noise ratio"
    },
    {
        " and the ratio between the ": null
    },
    {
        "sampling rate": "sampling rate"
    },
    {
        " and the highest frequency of the signal.         Parts of the design problem relate to the fact that certain requirements are described in the frequency domain while others are expressed in the signal domain and that these may contradict. For example, it is not possible to obtain a filter which has both an arbitrary impulse response and arbitrary frequency function. Other effects which refer to relations between the signal and frequency domain are     The uncertainty principle between the signal and frequency domains   The variance extension theorem   The asymptotic behaviour of one domain versus discontinuities in the other         As stated by the ": null
    },
    {
        "Gabor limit": "gabor limit"
    },
    {
        ", an uncertainty principle, the product of the width of the frequency function and the width of the impulse response cannot be smaller than a specific constant. This implies that if a specific frequency function is requested, corresponding to a specific frequency width, the minimum width of the filter in the signal domain is set. Vice versa, if the maximum width of the response is given, this determines the smallest possible width in the frequency.   This is a typical example of contradictory requirements where the filter design process may try to find a useful compromise.         Let \\sigma^_ be the variance of the input signal and let \\sigma^_ be the variance of the filter. The variance of the filter response, \\sigma^_ , is then given by     : \\sigma^_ \\sigma^_ + \\sigma^_     This means that \\sigma_ /math  math /math  math /math  math /math  ref  /ref  math /math math /math math /math math /math math /math math /math math /math ": null
    }
]