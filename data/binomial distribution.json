[
    {
        "            In ": null
    },
    {
        "probability theory": "probability theory"
    },
    {
        " and ": null
    },
    {
        "statistics": "statistics"
    },
    {
        ", the binomial distribution with parameters n and p is the ": null
    },
    {
        "discrete probability distribution": "discrete probability distribution"
    },
    {
        " of the number of successes in a sequence of n ": null
    },
    {
        "independent": "statistical independence"
    },
    {
        " experiment": "experiment"
    },
    {
        "s, each asking a ": null
    },
    {
        "yes–no question": "yes–no question"
    },
    {
        ", and each with its own ": null
    },
    {
        "boolean": "boolean-valued function"
    },
    {
        "-valued ": null
    },
    {
        "outcome": "outcome"
    },
    {
        ": ": null
    },
    {
        "success": "wikt:success"
    },
    {
        "/": null
    },
    {
        "yes": "yes and no"
    },
    {
        "/": null
    },
    {
        "true": "truth value"
    },
    {
        "/": null
    },
    {
        "one": "one"
    },
    {
        "  or ": null
    },
    {
        "failure": "failure"
    },
    {
        "/": null
    },
    {
        "no": "yes and no"
    },
    {
        "/": null
    },
    {
        "false": "false"
    },
    {
        "/": null
    },
    {
        "zero": "zero"
    },
    {
        " .   A single success/failure experiment is also called a ": null
    },
    {
        "Bernoulli trial": "bernoulli trial"
    },
    {
        " or Bernoulli experiment and a sequence of outcomes is called a ": null
    },
    {
        "Bernoulli process": "bernoulli process"
    },
    {
        "; for a single trial, i.e., n    1, the binomial distribution is a ": null
    },
    {
        "Bernoulli distribution": "bernoulli distribution"
    },
    {
        ". The binomial distribution is the basis for the popular ": null
    },
    {
        "binomial test": "binomial test"
    },
    {
        " of ": null
    },
    {
        "statistical significance": "statistical significance"
    },
    {
        ".     The binomial distribution is frequently used to model the number of successes in a sample of size n drawn ": null
    },
    {
        "with replacement": "with replacement"
    },
    {
        " from a population of size N. If the sampling is carried out without replacement, the draws are not independent and so the resulting distribution is a ": null
    },
    {
        "hypergeometric distribution": "hypergeometric distribution"
    },
    {
        ", not a binomial one. However, for N much larger than n, the binomial distribution remains a good approximation, and is widely used.             In general, if the ": null
    },
    {
        "random variable": "random variable"
    },
    {
        " X follows the binomial distribution with parameters n ": null
    },
    {
        "∈": "∈"
    },
    {
        " ℕ": "natural number"
    },
    {
        " and p ∈ we write X  ~  B. The probability of getting exactly k successes in n independent Bernoulli trials is given by the ": null
    },
    {
        "probability mass function": "probability mass function"
    },
    {
        ":     : f \\Pr \\Pr \\binomp^k^     for k    0,  1,  2,  ...,  n, where     : \\binom \\frac     is the ": null
    },
    {
        "binomial coefficient": "binomial coefficient"
    },
    {
        ", hence the name of the distribution. The formula can be understood as follows. k successes occur with probability p k and n  −  k failures occur with probability  n  −  k . However, the k successes can occur anywhere among the n trials, and there are \\binom different ways of distributing k successes in a sequence of n trials.     In creating reference tables for binomial distribution probability, usually the table is filled in up to n/2 values. This is because for k    math /math  math /math  ref  /ref math p.     f is monotone increasing for k     M, with the exception of the case where p is an integer. In this case, there are two values for which f is maximal: p and p  −  1. M is the most probable outcome of the Bernoulli trials and is called the ": null
    },
    {
        "mode": "mode"
    },
    {
        ".         The ": null
    },
    {
        "cumulative distribution function": "cumulative distribution function"
    },
    {
        " can be expressed as:     : F \\Pr \\sum_^ p^i^     where \\lfloor k\\rfloor\\, is the floor under k, i.e. the ": null
    },
    {
        "greatest integer": "greatest integer"
    },
    {
        " less than or equal to k.     It can also be represented in terms of the ": null
    },
    {
        "regularized incomplete beta function": "regularized incomplete beta function"
    },
    {
        ", as follows:      : \\begin   F & \\Pr \\\\   & I_ \\\\   & \\int_0^ t^ ^k \\, dt.   \\end     which is equivalent to the ": null
    },
    {
        "cumulative distribution function": "cumulative distribution function"
    },
    {
        " of the ": null
    },
    {
        "F-distribution": "f-distribution"
    },
    {
        " Jowett G H , The Relationship Between the Binomial and F Distributions, Journal of the Royal Statistical Society D, 13, 55-57.     :   F F_\\left.       Some closed-form bounds for the cumulative distribution function are given ": null
    },
    {
        "below": "tail bounds"
    },
    {
        ".         Suppose a ": null
    },
    {
        "biased coin": "fair coin"
    },
    {
        " comes up heads with probability 0.3 when tossed. What is the probability of achieving 0, 1,..., 6 heads after six tosses?     : \\Pr f \\Pr 0.3^0 ^ 0.117649   : \\Pr f \\Pr 0.3^1 ^ 0.302526   : \\Pr f \\Pr 0.3^2 ^ 0.324135   : \\Pr f \\Pr 0.3^3 ^ 0.18522   : \\Pr f \\Pr 0.3^4 ^ 0.059535   : \\Pr f \\Pr 0.3^5 ^ 0.010206   : \\Pr f \\Pr 0.3^6 ^ 0.000729 Hamilton Institute.  October 20, 2010.           If X ~ B, that is, X is a binomially distributed random variable, n being the total number of experiments and p the probability of each experiment yielding a successful result, then the ": null
    },
    {
        "expected value": "expected value"
    },
    {
        " of X is: See      : \\operatorname np.     This follows from the linearity of the expected value along with fact that  is the sum of  identical Bernoulli random variables, each with expected value . In other words, if X_1, \\ldots, X_n are identical Bernoulli random variables with parameter , then X X_1 + \\cdots + X_n and   : \\operatorname \\operatorname \\operatorname + \\cdots + \\operatorname p + \\cdots + p np.     The ": null
    },
    {
        "variance": "variance"
    },
    {
        " is:   : \\operatorname np.     This similarly follows from the fact that the variance of a sum of independent random variables is the sum of the variances.       The first 6 central moments are given by   : \\begin   \\mu_1 & 0, \\\\   \\mu_2 & np,\\\\   \\mu_3 & np,\\\\   \\mu_4 & np,\\\\   \\mu_5 & np,\\\\   \\mu_6 & np.   \\end         Usually the ": null
    },
    {
        "mode": "mode"
    },
    {
        " of a binomial B distribution is equal to \\lfloor p\\rfloor , where \\lfloor\\cdot\\rfloor is the ": null
    },
    {
        "floor function": "floor function"
    },
    {
        ". However, when p is an integer and p is neither 0 nor 1, then the distribution has two modes: p and p  −  1. When p is equal to 0 or 1, the mode will be 0 and n correspondingly. These cases can be summarized as follows:   : \\text   \\begin   \\lfloor \\,p\\rfloor & \\textp\\text, \\\\   \\,p\\ \\text\\ \\,p - 1 & \\textp\\in\\, \\\\   n & \\textp n + 1.   \\end     Proof: Let     : f\\binom nk p^k q^.     For p0 only f has a nonzero value with f1 . For p1 we find f1 and f0 for k\\neq n . This proves that the mode is 0 for p0 and n for p1 .     Let 0 n ": null
    }
]