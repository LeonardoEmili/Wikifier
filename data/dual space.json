[
    {
        "   In ": null
    },
    {
        "mathematics": "mathematics"
    },
    {
        ", any ": null
    },
    {
        "vector space": "vector space"
    },
    {
        " V has a corresponding dual vector space  consisting of all ": null
    },
    {
        "linear functionals": "linear functional"
    },
    {
        "on V, together with the vector space structure of ": null
    },
    {
        "pointwise": "pointwise"
    },
    {
        " addition and scalar multiplication by constants.     The dual space as defined above is defined for all vector spaces, and to avoid ambiguity may also be called the algebraic dual space. When defined for a ": null
    },
    {
        "topological vector space": "topological vector space"
    },
    {
        ", there is a subspace of the dual space, corresponding to continuous linear functionals, called the continuous dual space.     Dual vector spaces find application in many branches of mathematics that use vector spaces, such as in ": null
    },
    {
        "tensor": "tensor"
    },
    {
        " analysis with ": null
    },
    {
        "finite-dimensional": "finite-dimensional"
    },
    {
        " vector spaces. When applied to vector spaces of functions , dual spaces are used to describe ": null
    },
    {
        "measures": "measure"
    },
    {
        ", ": null
    },
    {
        "distributions": "distribution"
    },
    {
        ", and ": null
    },
    {
        "Hilbert space": "hilbert space"
    },
    {
        "s. Consequently, the dual space is an important concept in ": null
    },
    {
        "functional analysis": "functional analysis"
    },
    {
        ".       Given any ": null
    },
    {
        "vector space": "vector space"
    },
    {
        " V over a ": null
    },
    {
        "field": "field"
    },
    {
        " F, the  dual space V ∗ For V^\\vee used in this way, see p.  19 of https://archive.org/details/TuL.W.AnIntroductionToManifolds2e2010Springer An Introduction to Manifolds by Loring Tu. This notation is sometimes used when ^ is reserved for some other meaning. For instance, in the above text, F^ is frequently used to denote the codifferential of F, so that F^\\omega represents the pullback of the form ω.     Halmoss https://archive.org/details/HalmosP.R.FiniteDimensionalVectorSpaces.SpringerVerlag205s_201703 Finite-Dimensional Vector Spaces uses V to denote the algebraic dual of V ; see p.  20. However, other authors use V for the continuous dual, while reserving V^ for the algebraic dual.   is defined as the set of all ": null
    },
    {
        "linear maps": "linear map"
    },
    {
        "  . Since linear maps are vector space ": null
    },
    {
        "homomorphism": "homomorphism"
    },
    {
        "s, the dual space is also sometimes denoted by Hom. The dual space V ∗ itself becomes a vector space over F when equipped with an addition and scalar multiplication satisfying:   :   \\begin   & \\varphi + \\psi \\\\   & a \\left   \\end   for all φ and , , and . Elements of the algebraic dual space V ∗ are sometimes called covectors or  one-form s.     The pairing of a functional φ in the dual space V ∗ and an element x of V is sometimes denoted by a bracket:     or .  This pairing defines a nondegenerate ": null
    },
    {
        "bilinear mapping": "bilinear mapping"
    },
    {
        " In many areas, such as ": null
    },
    {
        "quantum mechanics": "quantum mechanics"
    },
    {
        ",  is reserved for a ": null
    },
    {
        "sesquilinear form": "sesquilinear form"
    },
    {
        " defined on .  called the ": null
    },
    {
        "natural pairing": "natural pairing"
    },
    {
        ".         If V is finite-dimensional, then V ∗ has the same dimension as V. Given a ": null
    },
    {
        "basis": "basis of a vector space"
    },
    {
        "  in V, it is possible to construct a specific basis in V ∗ , called the  dual basis . This dual basis is a set  of linear functionals on V, defined by the relation   : \\mathbf^i c^i, \\quad i1,\\ldots,n   for any choice of coefficients . In particular, letting in turn each one of those coefficients be equal to one and the other coefficients zero, gives the system of equations   : \\mathbf^i \\delta^_   where \\delta^_ is the ": null
    },
    {
        "Kronecker delta": "kronecker delta"
    },
    {
        " symbol. This property is referred to as biorthogonality property.     For example, if V is R 2 , let its basis be chosen as . Note that the basis vectors are not orthogonal to each other. Then, e 1 and e 2 are ": null
    },
    {
        "one-forms": "one-form"
    },
    {
        " such that , , , and . . We can express this system of equations using matrix notation as   :   \\begin   e_ & e_ \\\\   e_ & e_   \\end   \\begin   e^ & e^ \\\\   e^ & e^   \\end     \\begin   1 & 0 \\\\   0 & 1   \\end.     Solving this equation, we find the dual basis to be . Recalling that e 1 and e 2 are functionals, we can rewrite them as e 1  2x and e 2  −x + y. In general, when V is R n , if E  is a matrix whose columns are the basis vectors and Ê  is a matrix whose columns are the dual basis vectors, then   : E^T \\hat I_n,   where I n is an identity matrix of order n. The biorthogonality property of these two basis sets allows us to represent any point x in V as   : \\mathbf \\sum_i \\langle\\mathbf,\\mathbf^i \\rangle \\mathbf_i \\sum_i \\langle \\mathbf, \\mathbf_i \\rangle \\mathbf^i,   even when the basis vectors are not orthogonal to each other. Strictly speaking, the above statement only makes sense once the inner product \\langle \\cdot, \\cdot \\rangle and the corresponding duality pairing are introduced, as described below in ": null
    },
    {
        "Bilinear products and dual spaces": "dual_spacebilinear_products_and_dual_spaces"
    },
    {
        ".     In particular, if we interpret R n as the space of columns of n ": null
    },
    {
        "real number": "real number"
    },
    {
        "s, its dual space is typically written as the space of rows of n real numbers. Such a row acts on R n as a linear functional by ordinary ": null
    },
    {
        "matrix multiplication": "matrix multiplication"
    },
    {
        ". One way to see this is that a functional maps every n-vector x into a real number y. Then, seeing this functional as a matrix M, and x, y as a  matrix and a  matrix respectively, if we have , then, by dimension reasons, M must be a  matrix, i.e., M must be a row vector.     If V consists of the space of geometrical ": null
    },
    {
        "vectors": "vector"
    },
    {
        "in the plane, then the level curves of an element of V ∗ form a family of parallel lines in V, because the range is 1-dimensional, so that every point in the range is a multiple of any one nonzero element. So an element of V ∗ can be intuitively thought of as a particular family of parallel lines covering the plane. To compute the value of a functional on a given vector, one needs only to determine which of the lines the vector lies on. Or, informally, one counts how many lines the vector crosses. More generally, if V is a vector space of any dimension, then the level sets of a linear functional in V ∗ are parallel hyperplanes in V, and the action of a linear functional on a vector can be visualized in terms of these hyperplanes.        If V is not finite-dimensional but has a ": null
    },
    {
        "basis": "basis"
    },
    {
        " Several assertions in this article require the ": null
    },
    {
        "axiom of choice": "axiom of choice"
    },
    {
        " for their justification. The axiom of choice is needed to show that an arbitrary vector space has a basis: in particular it is needed to show that R N  has a basis. It is also needed to show that the dual of an infinite-dimensional vector space V is nonzero, and hence that the natural map from V to its double dual is injective. e α indexed by an infinite set A, then the same construction as in the finite-dimensional case yields ": null
    },
    {
        "linearly independent": "linearly independent"
    },
    {
        " elements e α  of the dual space, but they will not form a basis.     Consider, for instance, the space R ∞ , whose elements are those ": null
    },
    {
        "sequences": "sequence"
    },
    {
        "of real numbers that contain only finitely many non-zero entries, which has a basis indexed by the natural numbers N: for , e i is the sequence consisting of all zeroes except in the i-th position, which is 1. The dual space of R ∞ is R N , the space of all sequences of real numbers: such a sequence  is applied to an element  of R ∞ to give the number     : \\sum_n a_nx_n,     which is a finite sum because there are only finitely many nonzero x n . The ": null
    },
    {
        "dimension": "dimension"
    },
    {
        " of R ∞ is countably infinite, whereas R N  does not have a countable basis.     This observation generalizes to any infinite-dimensional vector space V over any field F: a choice of basis  identifies V with the space  0 of functions  such that  is nonzero for only finitely many , where such a function f is identified with the vector     : \\sum_ f_\\alpha\\mathbf_\\alpha     in V .     The dual space of V may then be identified with the space F A  of all functions from A to F: a linear functional T on V is uniquely determined by the values  it takes on the basis of V, and any function   defines a linear functional T on V by     : T\\left \\sum_ f_\\alpha T \\sum_ f_\\alpha \\theta_\\alpha.     Again the sum is finite because f α  is nonzero for only finitely many α.     Note that  0 may be identified with the ": null
    },
    {
        "direct sum": "direct sum of modules"
    },
    {
        " of infinitely many copies of F indexed by A, i.e., there are linear isomorphisms     : V\\cong _0\\cong\\bigoplus_ F.     On the other hand, F A  is , the ": null
    },
    {
        "direct product": "direct product"
    },
    {
        " of infinitely many copies of F indexed by A, and so the identification     : V^ \\cong \\left ^ \\cong \\prod_F^ \\cong \\prod_F \\cong F^A     is a special case of a ": null
    },
    {
        "general result": "direct sum of modulesproperties"
    },
    {
        " relating direct sums to direct products.     Thus if the basis is infinite, then the algebraic dual space is always of larger dimension  than the original vector space. This is in contrast to the case of the continuous dual space, discussed below, which may be ": null
    },
    {
        "isomorphic": "isomorphic"
    },
    {
        " to the original vector space even if the latter is infinite-dimensional.         If V is finite-dimensional, then V is isomorphic to V ∗ . But there is in general no ": null
    },
    {
        "natural isomorphism": "natural isomorphism"
    },
    {
        " between these two spaces.  Any ": null
    },
    {
        "bilinear form": "bilinear form"
    },
    {
        "  on V gives a mapping of V into its dual space via     : v\\mapsto \\langle v, \\cdot\\rangle     where the right hand side is defined as the functional on V taking each  to . In other words, the bilinear form determines a linear mapping     : \\Phi_ : V\\to V^     defined by     : \\left \\langle v, w\\rangle.     If the bilinear form is ": null
    },
    {
        "nondegenerate": "nondegenerate form"
    },
    {
        ", then this is an isomorphism onto a subspace of V ∗ . If V is finite-dimensional, then this is an isomorphism onto all of V ∗ . Conversely, any isomorphism \\Phi from V to a subspace of V ∗  defines a unique nondegenerate bilinear form  on V by     : \\langle v,w \\rangle_\\Phi \\,     Thus there is a one-to-one correspondence between isomorphisms of V to subspaces of V ∗ and nondegenerate bilinear forms on V.     If the vector space V is over the ": null
    },
    {
        "complex": "complex numbers"
    },
    {
        " field, then sometimes it is more natural to consider ": null
    },
    {
        "sesquilinear forms": "sesquilinear form"
    },
    {
        "instead of bilinear forms. In that case, a given sesquilinear form  determines an isomorphism of V with the ": null
    },
    {
        "complex conjugate": "complex conjugate vector space"
    },
    {
        " of the dual space     :   \\Phi_ : V\\to \\overline.     The conjugate space  V  ∗ can be identified with the set of all additive complex-valued functionals  such that   :   f \\overlinef.         There is a ": null
    },
    {
        "natural": "natural transformation"
    },
    {
        " homomorphism": "linear map"
    },
    {
        " \\Psi from V into the double dual V^\\ , defined by \\varphi for all v\\in V, \\varphi\\in V^ . In other words, if \\mathrm_v:V^\\to F is the evaluation map defined by \\varphi \\mapsto \\varphi , then we define \\Psi:V\\to V^ as the map v\\mapsto\\mathrm_v . This map \\Psi is always ": null
    },
    {
        "injective": "injective"
    },
    {
        "; it is an ": null
    },
    {
        "isomorphism": "isomorphism"
    },
    {
        " if and only if V is finite-dimensional.  Indeed, the isomorphism of a finite-dimensional vector space with its double dual is an archetypal example of a ": null
    },
    {
        "natural isomorphism": "natural isomorphism"
    },
    {
        ". Note that infinite-dimensional Hilbert spaces are not a counterexample to this, as they are isomorphic to their continuous duals, not to their algebraic duals.             If  is a ": null
    },
    {
        "linear map": "linear map"
    },
    {
        ", then the  transpose    is defined by   :   f^ \\varphi \\circ f \\,     for every . The resulting functional f in V is called the  pullback  of φ along f.     The following identity holds for all  and :   :       where the bracket on the left is the natural pairing of V with its dual space, and that on the right is the natural pairing of W with its dual. This identity characterizes the transpose,  and is formally similar to the definition of the ": null
    },
    {
        "adjoint": "adjoint of an operator"
    },
    {
        ".     The assignment  produces an ": null
    },
    {
        "injective": "injective"
    },
    {
        " linear map between the space of linear operators from V to W and the space of linear operators from W to V; this homomorphism is an ": null
    },
    {
        "isomorphism": "isomorphism"
    },
    {
        " if and only if W is finite-dimensional. If  then the space of linear maps is actually an ": null
    },
    {
        "algebra": "algebra over a field"
    },
    {
        " under ": null
    },
    {
        "composition of maps": "composition of maps"
    },
    {
        ", and the assignment is then an ": null
    },
    {
        "antihomomorphism": "antihomomorphism"
    },
    {
        " of algebras, meaning that . In the language of ": null
    },
    {
        "category theory": "category theory"
    },
    {
        ", taking the dual of vector spaces and the transpose of linear maps is therefore a ": null
    },
    {
        "contravariant functor": "contravariant functor"
    },
    {
        " from the category of vector spaces over F to itself. Note that one can identify  with f using the natural injection into the double dual.     If the linear map f is represented by the ": null
    },
    {
        "matrix": "matrix"
    },
    {
        " A with respect to two bases of V and W, then f is represented by the ": null
    },
    {
        "transpose": "transpose"
    },
    {
        " matrix A T with respect to the dual bases of W and V, hence the name. Alternatively, as f is represented by A acting on the left on column vectors, f is represented by the same matrix acting on the right on row vectors. These points of view are related by the canonical inner product on R n , which identifies the space of column vectors with the dual space of row vectors.       Let S be a subset of V. The  annihilator  of S in V ∗ , denoted here S, is the collection of linear functionals  such that  for all . That is, S consists of all linear functionals  such that the restriction to S vanishes: . Within finite dimensional vector spaces, the annihilator is dual to the ": null
    },
    {
        "orthogonal complement": "orthogonal complement"
    },
    {
        ".     The annihilator of a subset is itself a vector space. In particular, the annihilator of the zero vector is the whole dual space: \\^0 V^ , and the annihilator of the whole space is just the zero covector: V^0 \\ \\subset V^ . Furthermore, the assignment of an annihilator to a subset of V reverses inclusions, so that if , then   :   0 \\subset T^0 \\subset S^0 \\subset V^ .       Moreover, if A and B are two subsets of V, then   :   ^0 \\supseteq A^0 + B^0,     and equality holds provided V is finite-dimensional. If A i  is any family of subsets of V indexed by i belonging to some index set I, then   :   \\left^0 \\bigcap_ A_i^0 .     In particular if A and B are subspaces of V, it follows that   :   ^0 A^0 \\cap B^0 .       If V is finite-dimensional, and W is a ": null
    },
    {
        "vector subspace": "vector subspace"
    },
    {
        ", then   :   W^ W     after identifying W with its image in the second dual space under the double duality isomorphism . Thus, in particular, forming the annihilator is a ": null
    },
    {
        "Galois connection": "galois connection"
    },
    {
        " on the lattice of subsets of a finite-dimensional vector space.     If W is a subspace of V then the ": null
    },
    {
        "quotient space": "quotient space"
    },
    {
        " V/W is a vector space in its own right, and so has a dual. By the ": null
    },
    {
        "first isomorphism theorem": "first isomorphism theorem"
    },
    {
        ", a functional  factors through V/W if and only if W is in the ": null
    },
    {
        "kernel": "kernel"
    },
    {
        " of f. There is thus an isomorphism   : ^ \\cong W^0 .   As a particular consequence, if V is a ": null
    },
    {
        "direct sum": "direct sum of modules"
    },
    {
        " of two subspaces A and B, then V ∗ is a direct sum of A and B.        When dealing with ": null
    },
    {
        "topological vector space": "topological vector space"
    },
    {
        "s, one is typically only interested in the ": null
    },
    {
        "continuous": "continuous function"
    },
    {
        " linear functionals from the space into the base field \\mathbb\\C . This gives rise to the notion of the continuous dual space or topological dual which is a linear subspace of the algebraic dual space V^ , denoted by V . For any finite-dimensional normed vector space or topological vector space, such as ": null
    },
    {
        "Euclidean n-space": "euclidean space"
    },
    {
        ", the continuous dual and the algebraic dual coincide. This is however false for any infinite-dimensional normed space, as shown by the example of ": null
    },
    {
        "discontinuous linear map": "discontinuous linear map"
    },
    {
        "s. Nevertheless, in the theory of ": null
    },
    {
        "topological vector spaces": "topological vector space"
    },
    {
        "the terms continuous dual space and topological dual space are often replaced by dual space , since there is no serious need to consider discontinuous maps in this field.     For a ": null
    },
    {
        "topological vector space": "topological vector space"
    },
    {
        " V its continuous dual space,  or topological dual space,  or just dual space   V is defined as the space of all continuous linear functionals \\varphi:V\\to .     There is a standard construction for introducing a topology on the continuous dual V of a topological vector space V . Fix a collection \\mathcal of ": null
    },
    {
        "bounded subsets": "bounded set"
    },
    {
        " of V . Then one has the topology on V of uniform convergence on sets from \\mathcal, or what is the same thing, the topology generated by ": null
    },
    {
        "seminorms": "norm"
    },
    {
        " of the form     : \\|\\varphi\\|_A \\sup_ |\\varphi|,     where \\varphi is a continuous linear functional on V , and A runs over the class \\mathcal .     This means that a net of functionals \\varphi_i tends to a functional \\varphi in V if and only if     : \\forall A\\in\\mathcal\\qquad \\|\\varphi_i-\\varphi\\|_A \\sup_ |\\varphi_i-\\varphi|\\underset 0.     Usually the class \\mathcal is supposed to satisfy the following conditions:     each point x of V belongs to some set A\\in\\mathcal   :: \\forall x\\in V\\qquad \\exists A\\in \\mathcal\\qquad x\\in A,     each two sets A\\in\\mathcal and B\\in\\mathcal are contained in some set C\\in\\mathcal :   :: \\forall A,B\\in \\mathcal\\qquad \\exists C\\in \\mathcal\\qquad A\\cup B\\subseteq C,     \\mathcal is closed under the operation of multiplication by scalars:   :: \\forall A\\in \\mathcal\\qquad \\forall\\lambda\\in\\qquad \\lambda\\cdot A\\in \\mathcal,     If these requirements are fulfilled then the corresponding topology on V is Hausdorff and the sets     : U_A \\left \\": null
    }
]