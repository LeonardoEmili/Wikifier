{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/leo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bz2\n",
    "import nltk\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615243\n"
     ]
    }
   ],
   "source": [
    "train_file = bz2.BZ2File('../input_data/train.json.bz2')\n",
    "#test_file = bz2.BZ2File('../input_data/test.json.bz2')\n",
    "train_file = json.load(train_file)\n",
    "#test_file = json.load(test_file)\n",
    "print(len(train_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "link_treshold = 3\n",
    "valid_links = Counter([next(iter(sentence.values())) for sentence in train_file if next(iter(sentence.values())) is not None])\n",
    "valid_links = set([link for link,frequence in valid_links.items() if frequence >= link_treshold])\n",
    "\n",
    "for i, sentence in enumerate(train_file):\n",
    "    sentence, link = next(iter(sentence.items()))\n",
    "    train_file[i] = sentence.lower().strip()\n",
    "    if link in valid_links:\n",
    "        train_file[i] = \"_\" + train_file[i] + \"_\"\n",
    "        #train_file[i] = \"_\" + sentence.strip() + \"_\"\n",
    "        links.append(link)\n",
    "    #else:\n",
    "        #train_file[i] = sentence.lower()\n",
    "        #train_file[i] = sentence.strip()\n",
    "\n",
    "# check if the pairing is correct ... IT IS!\n",
    "# print(list(zip([s for s in train_file if s[0]==s[-1]==\"_\"][50:100], links[50:100])))\n",
    "\n",
    "train_file = nltk.sent_tokenize(\" \".join(train_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_domino_ tiles are usually rectangular, twice as long as they are wide and at least twice as wide as they are thick, though games exist with square tiles, triangular tiles and even hexagonal tiles.\n",
      "\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#print(list(nltk.word_tokenize(x) for x in train_file)[:10])\n",
    "print(train_file[4])\n",
    "print()\n",
    "print(\"Paracrine\" in links[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
