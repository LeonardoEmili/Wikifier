[
    {
        "Algorithms for calculating variance play a major role in ": null
    },
    {
        "computational statistics": "Computational Statistics"
    },
    {
        ". A key difficulty in the design of good ": null
    },
    {
        "algorithms": "Algorithm"
    },
    {
        "for this problem is that formulas for the ": null
    },
    {
        "variance": "Variance"
    },
    {
        " may involve sums of squares, which can lead to ": null
    },
    {
        "numerical instability": "Numerical Instability"
    },
    {
        " as well as to ": null
    },
    {
        "arithmetic overflow": "Arithmetic Overflow"
    },
    {
        " when dealing with large values.       A formula for calculating the variance of an entire ": null
    },
    {
        "population": "Statistical Population"
    },
    {
        " of size N is:     :     -   x2   .       Using ": null
    },
    {
        "Bessels correction": "Bessels Correction"
    },
    {
        " to calculate an ": null
    },
    {
        "unbiased": "Estimator Bias"
    },
    {
        " estimate of the population variance from a finite ": null
    },
    {
        "sample": "Statistical Sample"
    },
    {
        " of n observations, the formula is:     : s2       .       Therefore, a naive algorithm to calculate the estimated variance is given by the following:                      This algorithm can easily be adapted to compute the variance of a finite population: simply divide by N instead of n  âˆ’  1 on the last line.     Because  and  can be very similar numbers, ": null
    },
    {
        "cancellation": "Loss Of Significance"
    },
    {
        " can lead to the ": null
    },
    {
        "precision": "Precision"
    },
    {
        " of the result to be much less than the inherent precision of the ": null
    },
    {
        "floating-point arithmetic": "Floating-Point Arithmetic"
    },
    {
        " used to perform the computation. Thus this algorithm should not be used in practice,   and several alternate, numerically stable, algorithms have been proposed.  This is particularly bad if the standard deviation is small relative to the mean. However, the algorithm can be improved by adopting the method of the ": null
    },
    {
        "assumed mean": "Assumed Mean"
    },
    {
        ".         The variance is ": null
    },
    {
        "invariant": "Invariant"
    },
    {
        " with respect to changes in a ": null
    },
    {
        "location parameter": "Location Parameter"
    },
    {
        ", a property which can be used to avoid the catastrophic cancellation in this formula.     :       with K any constant, which leads to the new formula     : s2   .       the closer K is to the mean value the more accurate the result will be, but just choosing a value inside the   samples range will guarantee the desired stability. If the values are small then there are no problems with the sum of its squares, on the contrary, if they are large it necessarily means that the variance is large as well. In any case the second term in the formula is always smaller than the first one therefore no cancellation may occur.     If just the first sample is taken as K the algorithm can be written in ": null
    },
    {
        "Python programming language": "Python"
    },
    {
        " as        def shifteddatavariance:   if len ": null
    }
]