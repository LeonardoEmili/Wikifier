         Propositional calculus is a branch of  |logic|Logic| . It is also called propositional logic, statement logic, sentential calculus, sentential logic, or sometimes  zeroth-order logic . It deals with  |propositions|Propositions|  and argument flow. Compound propositions are formed by connecting propositions by  |logical_connectives|Logical_Connective| . The propositions without logical connectives are called atomic propositions.     Unlike  |first_order_logic|First_Order_Logic| , propositional logic does not deal with non-logical objects, predicates about them, or quantifiers. However, all the machinery of propositional logic is included in first-order logic and higher-order logics. In this sense, propositional logic is the foundation of first-order logic and higher-order logic.       Logical connectives are found in natural languages. In English for example, some examples are and , or , not  and if .     The following is an example of a very simple inference within the scope of propositional logic:     :Premise 1: If its raining then its cloudy.   :Premise 2: Its raining.   :Conclusion: Its cloudy.     Both premises and the conclusion are propositions. The premises are taken for granted and then with the application of  |modus_ponens|Modus_Ponens|   the conclusion follows.     As propositional logic is not concerned with the structure of propositions beyond the point where they cant be decomposed any more by logical connectives, this inference can be restated replacing those atomic statements with statement letters, which are interpreted as variables representing statements:     :Premise 1: P   Q   :Premise 2: P   :Conclusion: Q     The same can be stated succinctly in the following way:     : P   Q, P   Q     When  is interpreted as Its raining and  as its cloudy the above symbolic expressions can be seen to exactly correspond with the original expression in natural language. Not only that, but they will also correspond with any other inference of this form, which will be valid on the same basis that this inference is.     Propositional logic may be studied through a  |formal_system|Formal_System|  in which  |formulas|Well_Formed_Formula|  of a  |formal_language|Formal_Language|  may be  |interpreted|Interpretation|  to represent  |propositions|Propositions| . A  |system|Deductive_System|  of  |inference_rules|Rule_Of_Inference|  and  |axioms|Axiom|  allows certain formulas to be derived. These derived formulas are called  |theorems|Theorem|  and may be interpreted to be true propositions. A constructed sequence of such formulas is known as a  derivation  or proof and the last formula of the sequence is the theorem. The derivation may be interpreted as proof of the proposition represented by the theorem.     When a  |formal_system|Formal_System|  is used to represent formal logic, only statement letters are represented directly. The natural language propositions that arise when theyre interpreted are outside the scope of the system, and the relation between the formal system and its interpretation is likewise outside the formal system itself.     In classical truth-functional propositional logic, formulas are interpreted as having precisely one of two possible  |truth_values|Truth_Value| , the truth value of true or the truth value of false. The  |principle_of_bivalence|Principle_Of_Bivalence|  and the  |law_of_excluded_middle|Law_Of_Excluded_Middle|  are upheld. Truth-functional propositional logic defined as such and systems  |isomorphic|Isomorphism|  to it are considered to be  zeroth-order logic . However, alternative propositional logics are possible. See  |Other_logical_calculi|Propositional_Calculusalternative_Calculus|  below.          Although propositional logic had been hinted by earlier philosophers, it was developed into a formal logic  by  |Chrysippus|Chrysippus|  in the 3rd century BC  and expanded by his successor  |Stoics|Stoics| . The logic was focused on  |propositions|Proposition| . This advancement was different from the traditional  |syllogistic_logic|Syllogism|  which was focused on  |terms|Syllogismsterms_In_Syllogism| . However, later in antiquity, the propositional logic developed by the Stoics was no longer understood . Consequently, the system was essentially reinvented by  |Peter_Abelard|Peter_Abelard|  in the 12th century.      Propositional logic was eventually refined using  |symbolic_logic|Symbolic_Logic| . The 17th/18th-century mathematician  |Gottfried_Leibniz|Gottfried_Leibniz|  has been credited with being the founder of symbolic logic for his work with the  |calculus_ratiocinator|Calculus_Ratiocinator| . Although his work was the first of its kind, it was unknown to the larger logical community. Consequently, many of the advances achieved by Leibniz were recreated by logicians like  |George_Boole|George_Boole|  and  |Augustus_De_Morgan|Augustus_De_Morgan|  completely independent of Leibniz.      Just as propositional logic can be considered an advancement from the earlier syllogistic logic,  |Gottlob_Freges|Gottlob_Frege| |_predicate_logic|Predicate_Logic|  was an advancement from the earlier propositional logic. One author describes predicate logic as combining the distinctive features of syllogistic logic and propositional logic.  Consequently, predicate logic ushered in a new era in logics history; however, advances in propositional logic were still made after Frege, including  |Natural_Deduction|Natural_Deduction| ,  |Truth_Trees|Method_Of_Analytic_Tableaux|  and  |Truth_Tables|Truth_Table| . Natural deduction was invented by  |Gerhard_Gentzen|Gerhard_Gentzen|  and  |Jan_Łukasiewicz|Jan_Łukasiewicz| . Truth-Trees were invented by  |Evert_Willem_Beth|Evert_Willem_Beth| . Beth, Evert W.; Semantic entailment and formal derivability , series: Mededlingen van de Koninklijke Nederlandse Akademie van Wetenschappen, Afdeling Letterkunde, Nieuwe Reeks, vol. 18, no. 13, Noord-Hollandsche Uitg. Mij., Amsterdam, 1955, pp. 309–42. Reprinted in Jaakko Intikka The Philosophy of Mathematics, Oxford University Press, 1969 The invention of truth-tables, however, is of uncertain attribution.     Within works by Frege  and  |Bertrand_Russell|Bertrand_Russell| ,  are ideas influential to the invention of truth tables. The actual tabular structure , itself, is generally credited to either  |Ludwig_Wittgenstein|Ludwig_Wittgenstein|  or  |Emil_Post|Emil_Post|  . Besides Frege and Russell, others credited with having ideas preceding truth-tables include Philo, Boole,  |Charles_Sanders_Peirce|Charles_Sanders_Peirce| ,  and  |Ernst_Schröder|Ernst_Schröder| . Others credited with the tabular structure include  |Jan_Łukasiewicz|Jan_Łukasiewicz| ,  |Ernst_Schröder|Ernst_Schröder| ,  |Alfred_North_Whitehead|Alfred_North_Whitehead| ,  |William_Stanley_Jevons|William_Stanley_Jevons| ,  |John_Venn|John_Venn| , and  |Clarence_Irving_Lewis|Clarence_Irving_Lewis| . Ultimately, some have concluded, like John Shosky, that It is far from clear that any one person should be given the title of inventor of truth-tables. .       In general terms, a calculus is a  |formal_system|Formal_System|  that consists of a set of syntactic expressions , a distinguished subset of these expressions , plus a set of formal rules that define a specific  |binary_relation|Binary_Relation| , intended to be interpreted as  |logical_equivalence|Logical_Equivalence| , on the space of expressions.     When the formal system is intended to be a  |logical_system|Logical_System| , the expressions are meant to be interpreted as statements, and the rules, known to be inference rules, are typically intended to be truth-preserving. In this setting, the rules  can then be used to derive formulas representing true statements from given formulas representing true statements.     The set of axioms may be empty, a nonempty finite set, or a countably infinite set . A  |formal_grammar|Formal_Grammar|  recursively defines the expressions and well-formed formulas of the  |language|Formal_Language| . In addition a  |semantics|Semantics|  may be given which defines truth and  |valuations|Valuation|  .     The  |language|Formal_Language|  of a propositional calculus consists of   a set of primitive symbols, variously referred to as  atomic formula s, placeholders, proposition letters, or variables, and   a set of operator symbols, variously interpreted as  logical operator s or logical connectives.     A  well-formed formula  is any atomic formula, or any formula that can be built up from atomic formulas by means of operator symbols according to the rules of the grammar.     Mathematicians sometimes distinguish between propositional constants, propositional variables, and schemata. Propositional constants represent some particular proposition, while propositional variables range over the set of all atomic propositions. Schemata, however, range over all propositions. It is common to represent propositional constants by , , and , propositional variables by , , and , and schematic letters are often Greek letters, most often , , and .       The following outlines a standard propositional calculus. Many different formulations exist which are all more or less equivalent but differ in the details of:   their language, that is, the particular collection of primitive symbols and operator symbols,   the set of axioms, or distinguished formulas, and   the set of inference rules.     Any given proposition may be represented with a letter called a propositional constant, analogous to representing a number by a letter in mathematics, for instance, . All propositions require exactly one of two truth-values: true or false. For example, let  be the proposition that it is raining outside. This will be true  if it is raining outside and false otherwise .     We then define  |truth_functional|Truth_Functional|  operators, beginning with negation.  represents the negation of , which can be thought of as the denial of . In the example above,  expresses that it is not raining outside, or by a more standard reading: It is not the case that it is raining outside. When  is true,  is false; and when  is false,  is true.  always has the same truth-value as .   Conjunction is a truth-functional connective which forms a proposition out of two simpler propositions, for example,  and . The conjunction of  and  is written , and expresses that each are true. We read  as  and  . For any two propositions, there are four possible assignments of truth values:    is true and  is true    is true and  is false    is false and  is true    is false and  is false   :The conjunction of  and  is true in case 1 and is false otherwise. Where  is the proposition that it is raining outside and  is the proposition that a cold-front is over Kansas,  is true when it is raining outside and there is a cold-front over Kansas. If it is not raining outside, then  is false; and if there is no cold-front over Kansas, then  is false.   Disjunction resembles conjunction in that it forms a proposition out of two simpler propositions. We write it , and it is read  or  . It expresses that either  or  is true. Thus, in the cases listed above, the disjunction of  with  is true in all cases except case 4. Using the example above, the disjunction expresses that it is either raining outside or there is a cold front over Kansas.    Material conditional also joins two simpler propositions, and we write , which is read if  then  . The proposition to the left of the arrow is called the antecedent and the proposition to the right is called the consequent. It expresses that  is true whenever  is true. Thus  is true in every case above except case 2, because this is the only case when  is true but  is not. Using the example, if  then  expresses that if it is raining outside then there is a cold-front over Kansas. The material conditional is often confused with physical causation. The material conditional, however, only relates two propositions by their truth-values—which is not the relation of cause and effect. It is contentious in the literature whether the material implication represents logical causation.   Biconditional joins two simpler propositions, and we write , which is read  if and only if  . It expresses that  and  have the same truth-value, and so, in cases 1 and 4,  is true if and only if  is true, and false otherwise.     It is extremely helpful to look at the  |truth_tables|Truth_Table|  for these different operators, as well as the  |method_of_analytic_tableaux|Method_Of_Analytic_Tableaux| .       Propositional logic is closed under truth-functional connectives. That is to say, for any proposition ,  is also a proposition. Likewise, for any propositions  and ,  is a proposition, and similarly for disjunction, conditional, and biconditional. This implies that, for instance,  is a proposition, and so it can be conjoined with another proposition. In order to represent this, we need to use parentheses to indicate which proposition is conjoined with which. For instance,  is not a well-formed formula, because we do not know if we are conjoining  with  or if we are conjoining  with . Thus we must write either  to represent the former, or  to represent the latter. By evaluating the truth conditions, we see that both expressions have the same truth conditions , and moreover that any proposition formed by arbitrary conjunctions will have the same truth conditions, regardless of the location of the parentheses. This means that conjunction is associative, however, one should not assume that parentheses never serve a purpose. For instance, the sentence  does not have the same truth conditions of , so they are different sentences distinguished only by the parentheses. One can verify this by the truth-table method referenced above.     Note: For any arbitrary number of propositional constants, we can form a finite number of cases which list their possible truth-values. A simple way to generate this is by truth-tables, in which one writes , , ..., , for any list of  propositional constants—that is to say, any list of propositional constants with  entries. Below this list, one writes  rows, and below  one fills in the first half of the rows with true and the second half with false . Below  one fills in one-quarter of the rows with T, then one-quarter with F, then one-quarter with T and the last quarter with F. The next column alternates between true and false for each eighth of the rows, then sixteenths, and so on, until the last propositional constant varies between T and F for each row. This will give a complete listing of cases or truth-value assignments possible for those propositional constants.       The propositional calculus then defines an  argument  to be a list of propositions. A valid argument is a list of propositions, the last of which follows from—or is implied by—the rest. All other arguments are invalid. The simplest valid argument is  |modus_ponens|Modus_Ponens| , one instance of which is the following list of propositions:     :       1. & P   Q     2. & P           & Q           This is a list of three propositions, each line is a proposition, and the last follows from the rest. The first two lines are called premises, and the last line the conclusion. We say that any proposition  follows from any set of propositions , if  must be true whenever every member of the set is true. In the argument above, for any  and , whenever  and  are true, necessarily  is true. Notice that, when  is true, we cannot consider cases 3 and 4 . When  is true, we cannot consider case 2. This leaves only case 1, in which  is also true. Thus  is implied by the premises.     This generalizes schematically. Thus, where  and  may be any propositions at all,     :       1. &           2. &             &             Other argument forms are convenient, but not necessary. Given a complete set of axioms , modus ponens is sufficient to prove all other argument forms in propositional logic, thus they may be considered to be a derivative. Note, this is not true of the extension of propositional logic to other logics like  |first_order_logic|First_Order_Logic| . First-order logic requires at least one additional rule of inference in order to obtain  |completeness|Completeness| .     The significance of argument in formal logic is that one may obtain new truths from established truths. In the first example above, given the two premises, the truth of  is not yet known or stated. After the argument is made,  is deduced. In this way, we define a deduction system to be a set of all propositions that may be deduced from another set of propositions. For instance, given the set of propositions A   , we can define a deduction system, , which is the set of all propositions which follow from .  |Reiteration|Deduction_Theoremvirtual_Rules_Of_Inference|  is always assumed, so P   Q,   Q   R,   R     . Also, from the first element of , last element, as well as modus ponens,  is a consequence, and so R     . Because we have not included sufficiently complete axioms, though, nothing else may be deduced. Thus, even though most deduction systems studied in propositional logic are able to deduce   , this one is too weak to prove such a proposition.       A propositional calculus is a  |formal_system|Formal_System|        , where:     The alpha set   is a countably infinite set of elements called proposition symbols or  propositional variable s. Syntactically speaking, these are the most basic elements of the formal language   , otherwise referred to as  atomic formula s or terminal elements. In the examples to follow, the elements of   are typically the letters , , , and so on.   The omega set  is a finite set of elements called  operator symbols  or  logical connective s. The set  is  |partitioned|Partition_Of_A_Set|  into disjoint subsets as follows:     :::                             :In this partition,   is the set of operator symbols of  arity  .     :In the more familiar propositional calculi,  is typically partitioned as follows:     :::         :::           :A frequently adopted convention treats the constant  |logical_values|Logical_Value|  as operators of arity zero, thus:     :::         :Some writers use the  |tilde|Tilde|  , or N, instead of ; and some use the  |ampersand|Ampersand|  , the prefixed K, or   instead of   . Notation varies even more for the set of logical values, with symbols like , , or all being seen in various contexts instead of   .     The zeta set   is a finite set of transformation rules that are called  inference rule s when they acquire logical applications.   The iota set   is a countable set of initial points that are called  axiom s when they receive logical interpretations.     The language of   , also known as its set of formulas,  well-formed formula s, is  |inductively_defined|Inductive_Definition|  by the following rules:     Base: Any element of the alpha set   is a formula of   .   If p1, p2,   pj are formulas and f is in   , then   is a formula.   Closed: Nothing else is a formula of   .     Repeated applications of these rules permits the construction of complex formulas. For example:     By rule 1,  is a formula.   By rule 2,   p is a formula.   By rule 1,  is a formula.   By rule 2, is a formula.       Let     , where   ,   ,   ,   are defined as follows:     The alpha set   , is a countably infinite set of symbols, for example:     :::         Of the three connectives for conjunction, disjunction, and implication , one can be taken as primitive and the other two can be defined in terms of it and negation . Wernick, William Complete Sets of Logical Functions, Transactions of the American Mathematical Society 51, pp. 117  132. Indeed, all of the logical connectives can be defined in terms of a  |sole_sufficient_operator|Sole_Sufficient_Operator| . The biconditional  can of course be defined in terms of conjunction and implication, with a   b defined as   .   :Adopting negation and implication as the two primitive operations of a propositional calculus is tantamount to having the omega set         partition as follows:     :::       :::         An axiom system discovered by  |Jan_Łukasiewicz|Jan_Łukasiewicz|  formulates a propositional calculus in this language as follows. The axioms are all  |substitution_instances|Substitution_Instance|  of:     ::     ::     ::     The rule of inference is  |modus_ponens|Modus_Ponens|  . Then a   b is defined as   a   b , and a   b is defined as   . This system is used in  |Metamath|Metamath|   formal proof database.       Let     , where   ,   ,   ,   are defined as follows:     The alpha set   , is a countably infinite set of symbols, for example:   :       The omega set         partitions as follows:   :       :         In the following example of a propositional calculus, the transformation rules are intended to be interpreted as the inference rules of a so-called  natural deduction system . The particular system presented here has no initial points, which means that its interpretation for logical applications derives its  |theorems|Theorem|  from an empty axiom set.     The set of initial points is empty, that is,     .   The set of transformation rules,   , is described as follows:     Our propositional calculus has eleven inference rules. These rules allow us to derive other true formulas given a set of formulas that are assumed to be true. The first ten simply state that we can infer certain well-formed formulas from other well-formed formulas. The last rule however uses hypothetical reasoning in the sense that in the premise of the rule we temporarily assume an hypothesis to be part of the set of inferred formulas to see if we can infer a certain other formula. Since the first ten rules dont do this they are usually described as non-hypothetical rules, and the last one as a hypothetical rule.     In describing the transformation rules, we may introduce a metalanguage symbol   . It is basically a convenient shorthand for saying infer that . The format is       , in which  is a set of formulas called premises, and  is a formula called conclusion. The transformation rule       means that if every proposition in  is a theorem , then  is also a theorem. Note that considering the following rule  |Conjunction_introduction|Conjunction_Introduction| , we will know whenever  has more than one formula, we can always safely reduce it into one formula using conjunction. So for short, from that time on we may represent  as one formula instead of a set. Another omission for convenience is when  is an empty set, in which case  may not appear.     ;  |Negation_introduction|Negation_Introduction| |Negation_elimination|Negation_Elimination| |Double_negation_elimination|Double_Negation_Elimination| .   : That is,     p   p .   ;  |Conjunction_introduction|Conjunction_Introduction|  and , infer .   : That is,     .   ;  |Conjunction_elimination|Conjunction_Elimination| .   : From , infer .   : That is,   p and   q .   ;  |Disjunction_introduction|Disjunction_Introduction| , infer .   : From , infer .   : That is, p   and q   .   ;  |Disjunction_elimination|Disjunction_Elimination| .   : That is,     r .   ;  |Biconditional_introduction|Biconditional_Introduction| |Biconditional_elimination|Biconditional_Elimination| |Modus_ponens|Modus_Ponens|  : From  and , infer .   : That is,     q .   ;  |Conditional_proof|Conditional_Proof|  : From accepting  allows a proof of , infer .   : That is,   .                One of the main uses of a propositional calculus, when interpreted for logical applications, is to determine relations of logical equivalence between propositional formulas. These relationships are determined by means of the available transformation rules, sequences of which are called derivations or proofs.     In the discussion to follow, a proof is presented as a sequence of numbered lines, with each line consisting of a single formula followed by a reason or justification for introducing that formula. Each premise of the argument, that is, an assumption introduced as an hypothesis of the argument, is listed at the beginning of the sequence and is marked as a premise in lieu of other justification. The conclusion is listed on the last line. A proof is complete if every line follows from the previous ones by the correct application of a transformation rule. .       To be shown that .   One possible proof of this may be arranged as follows:          Interpret A   A as Assuming , infer  . Read   A   A as Assuming nothing, infer that  implies  , or It is a tautology that  implies  , or It is always true that  implies  .       The crucial properties of this set of rules are that they are  sound  and complete. Informally this means that the rules are correct and that no other rules are required. These claims can be made more formal as follows.     We define a truth assignment as a  |function|Function|  that maps propositional variables to true or false. Informally such a truth assignment can be understood as the description of a possible  |state_of_affairs|State_Of_Affairs|   where certain statements are true and others are not. The semantics of formulas can then be formalized by defining for which state of affairs they are considered to be true, which is what is done by the following definition.     We define when such a truth assignment  satisfies a certain  |well_formed_formula|Well_Formed_Formula|  with the following rules:    satisfies the propositional variable   |if_and_only_if|If_And_Only_If|    satisfies  if and only if  does not satisfy   satisfies  if and only if  satisfies both  and   satisfies  if and only if  satisfies at least one of either  or   satisfies  if and only if it is not the case that  satisfies  but not   satisfies  if and only if  satisfies both  and  or satisfies neither one of them     With this definition we can now formalize what it means for a formula  to be implied by a certain set  of formulas. Informally this is true if in all worlds that are possible given the set of formulas  the formula  also holds. This leads to the following formal definition: We say that a set  of well-formed formulas semantically entails  a certain well-formed formula  if all truth assignments that satisfy all the formulas in  also satisfy .     Finally we define syntactical entailment such that  is syntactically entailed by  if and only if we can derive it with the inference rules that were presented above in a finite number of steps. This allows us to formulate exactly what it means for the set of inference rules to be sound and complete:     Soundness: If the set of well-formed formulas  syntactically entails the well-formed formula  then  semantically entails .     Completeness: If the set of well-formed formulas  semantically entails the well-formed formula  then  syntactically entails .     For the above set of rules this is indeed the case.            Notational conventions: Let  be a variable ranging over sets of sentences. Let  and  range over sentences. For  syntactically entails  we write  proves  . For  semantically entails  we write  implies  .     We want to show:  .     We note that  proves  has an inductive definition, and that gives us the immediate resources for demonstrating claims of the form If  proves , then ... . So our proof proceeds by induction.        Notice that Basis Step II can be omitted for  |natural_deduction|Natural_Deduction|  systems because they have no axioms. When used, Step II involves showing that each of the axioms is a  |logical_truth|Logical_Truth| .     The Basis steps demonstrate that the simplest provable sentences from  are also implied by , for any . The Inductive step will systematically cover all the further sentences that might be provable—by considering each case where we might reach a logical conclusion using an inference rule—and shows that if a new sentence is provable, it is also logically implied.  Generally, the Inductive step will consist of a lengthy but simple  |case_by_case_analysis|Proof_By_Cases|  of all the rules of inference, showing that each preserves semantic implication.     By the definition of provability, there are no sentences provable other than by being a member of , an axiom, or following by a rule; so if all of those are semantically implied, the deduction calculus is sound.           We adopt the same notational conventions as above.     We want to show: If  implies , then  proves . We proceed by  |contraposition|Contraposition|  does not prove  then  does not imply . If we show that there is a  |model|Mathematical_Model|  where  does not hold despite  being true, then obviously  does not imply . The idea is to build such a model out of our very assumption that  does not prove .           |QED|Q_E_D_|        If a formula is a  |tautology|Tautology| , then there is a  |truth_table|Truth_Table|  for it which shows that each valuation yields the value true for the formula. Consider such a valuation. By mathematical induction on the length of the subformulas, show that the truth or falsity of the subformula follows from the truth or falsity of each propositional variable in the subformula. Then combine the lines of the truth table together two at a time by using  implies  . Keep repeating this until all dependencies on propositional variables have been eliminated. The result is that we have proved the given tautology. Since every tautology is provable, the logic is complete.       An interpretation of a truth-functional propositional calculus   is an  |assignment|Assignment|  to each  |propositional_symbol|Propositional_Variable|  of   of one or the other of the  |truth_values|Truth_Value| |_truth|Truth|   and  |falsity|False|  , and an assignment to the  |connective_symbols|Logical_Connective|  of   of their usual truth-functional meanings. An interpretation of a truth-functional propositional calculus may also be expressed in terms of  |truth_tables|Truth_Tables| .      For n distinct propositional symbols there are 2n distinct possible interpretations. For any particular symbol a , for example, there are 212 possible interpretations:   a is assigned T, or   a is assigned F.   For the pair a , b there are 224 possible interpretations:   both are assigned T,   both are assigned F,   a is assigned T and b is assigned F, or   a is assigned F and b is assigned T.     Since   has   , that is,  |denumerably|Denumerably_Infinite|  many propositional symbols, there are 2  c , and therefore  |uncountably_many|Cardinality_Of_The_Continuum|  distinct possible interpretations of   .            If  and  are  |formulas|Formula|  of   and   is an interpretation of   then:     A sentence of propositional logic is true under an interpretation   iff   assigns the truth value T to that sentence. If a sentence is  |true|Logical_Truth|  under an interpretation, then that interpretation is called a model of that sentence.    is false under an interpretation   iff  is not true under   .   A sentence of propositional logic is logically valid if it is true under every interpretation.   :    means that  is logically valid.   A sentence  of propositional logic is a  semantic consequence  of a sentence  iff there is no interpretation under which  is true and  is false.   A sentence of propositional logic is  consistent  iff it is true under at least one interpretation. It is inconsistent if it is not consistent.     Some consequences of these definitions:     For any given interpretation a given formula is either true or false.   No formula is both true and false under the same interpretation.    is false for a given interpretation iff   is true for that interpretation; and  is true under an interpretation iff   is false under that interpretation.   If  and are both true under a given interpretation, then  is true under that interpretation.   If   and   , then   .     is true under   iff  is not true under   .   is true under   iff either  is not true under   or  is true under   .   A sentence  of propositional logic is a semantic consequence of a sentence  iff is  |logically_valid|Logically_Valid| , that is,       iff   .       It is possible to define another version of propositional calculus, which defines most of the syntax of the logical operators by means of axioms, and which uses only one inference rule.       Let , , and  stand for well-formed formulas. Then the axioms are as follows:       may be considered to be a distributive property of implication with respect to implication.   Axioms  and  correspond to conjunction elimination . The relation between  and  reflects the commutativity of the conjunction operator.   Axiom  corresponds to conjunction introduction.   Axioms  and  correspond to disjunction introduction. The relation between  and  reflects the commutativity of the disjunction operator.   Axiom  corresponds to reductio ad absurdum.   Axiom  says that anything can be deduced from a contradiction.   Axiom  is called  |tertium_non_datur|Law_Of_Excluded_Middle|   and reflects the semantic valuation of propositional formulas: a formula can have a truth-value of either true or false. There is no third truth-value, at least not in classical logic.  |Intuitionistic_logic|Intuitionistic_Logic| ians do not accept the axiom .       The inference rule is  |modus_ponens|Modus_Ponens| |turnstile|Turnstile|  and the conclusion to the right of the turnstile. Then the  |deduction_theorem|Deduction_Theorem|  can be stated as follows:   : If the sequence   ::         ... ,               : has been demonstrated, then it is also possible to demonstrate the sequence   ::         ...,             .     This deduction theorem is not itself formulated with propositional calculus: it is not a theorem of propositional calculus, but a theorem about propositional calculus. In this sense, it is a  |meta_theorem|Meta_Theorem| , comparable to theorems about the soundness or completeness of propositional calculus.     On the other hand, DT is so useful for simplifying the syntactical proof process that it can be considered and used as another inference rule, accompanying modus ponens. In this sense, DT corresponds to the natural  |conditional_proof|Conditional_Proof|  inference rule which is part of the first version of propositional calculus introduced in this article.     The converse of DT is also valid:   : If the sequence   ::         ...,               : has been demonstrated, then it is also possible to demonstrate the sequence   ::         ... ,               in fact, the validity of the converse of DT is almost trivial compared to that of DT:   : If   ::     ... ,               : then   :: 1:     ... ,                   :: 2:     ... ,               : and from and can be deduced   :: 3:     ... ,               : by means of modus ponens, Q.E.D.     The converse of DT has powerful implications: it can be used to convert an axiom into an inference rule. For example, the axiom AND-1,   :               can be transformed by means of the converse of the deduction theorem into the inference rule   :             which is  |conjunction_elimination|Conjunction_Elimination| , one of the ten inference rules used in the first version of the propositional calculus.       The following is an example of a demonstration, involving only axioms  and Prove: A   A .     Proof:       : Axiom  with   A,   B   A,   A   A     : Axiom  with   A,   B   A       : From and by modus ponens.   A     : Axiom  with   A,   B   A   A   : From and by modus ponens.       The preceding alternative calculus is an example of a  |Hilbert_style_deduction_system|Hilbert_Style_Deduction_System| . In the case of propositional systems the axioms are terms built with logical connectives and the only inference rule is modus ponens. Equational logic as standardly used informally in high school algebra is a different kind of calculus from Hilbert systems. Its theorems are equations and its inference rules express the properties of equality, namely that it is a congruence on terms that admits substitution.     Classical propositional calculus as described above is equivalent to  |Boolean_algebra|Boolean_Algebra| , while  |intuitionistic_propositional_calculus|Intuitionistic_Logic|  is equivalent to  |Heyting_algebra|Heyting_Algebra| . The equivalence is shown by translation in each direction of the theorems of the respective systems. Theorems   of classical or intuitionistic propositional calculus are translated as equations   1 of Boolean or Heyting algebra respectively. Conversely theorems x y of Boolean or Heyting algebra are translated as theorems   of classical or intuitionistic calculus respectively, for which x   y is a standard abbreviation. In the case of Boolean algebra x y can also be translated as   , but this translation is incorrect intuitionistically.     In both Boolean and Heyting algebra, inequality x   y can be used in place of equality. The equality x y is expressible as a pair of inequalities x   y and y   x . Conversely the inequality x   y is expressible as the equality x   y x , or as x   y y . The significance of inequality for Hilbert-style systems is that it corresponds to the latters deduction or  |entailment|Entailment|  symbol   . An entailment   ::                       is translated in the inequality version of the algebraic framework as   ::                             Conversely the algebraic inequality x   y is translated as the entailment   :: x    y .     The difference between implication x   y and inequality or  |entailment|Entailment|  x   y or x    y is that the former is internal to the logic while the latter is external. Internal implication between two terms is another term of the same kind. Entailment as external implication between two terms expresses a metatruth outside the language of the logic, and is considered part of the  |metalanguage|Metalanguage| . Even when the logic under study is intuitionistic, entailment is ordinarily understood classically as two-valued: either the left side entails, or is less-or-equal to, the right side, or it is not.     Similar but more complex translations to and from algebraic logics are possible for natural deduction systems as described above and for the  |sequent_calculus|Sequent_Calculus| . The entailments of the latter can be interpreted as two-valued, but a more insightful interpretation is as a set, the elements of which can be understood as abstract proofs organized as the morphisms of a  |category|Category| . In this interpretation the cut rule of the sequent calculus corresponds to composition in the category. Boolean and Heyting algebras enter this picture as special categories having at most one morphism per homset, i.e., one proof per entailment, corresponding to the idea that existence of proofs is all that matters: any proof will do and there is no point in distinguishing them.          It is possible to generalize the definition of a formal language from a set of finite sequences over a finite basis to include many other sets of mathematical structures, so long as they are built up by finitary means from finite materials. Whats more, many of these families of formal structures are especially well-suited for use in logic.     For example, there are many families of  |graphs|Graph|  that are close enough analogues of formal languages that the concept of a calculus is quite easily and naturally extended to them. Indeed, many species of graphs arise as  parse graph s in the syntactic analysis of the corresponding families of text structures. The exigencies of practical computation on formal languages frequently demand that text strings be converted into  |pointer_structure|Pointer_Structure|  renditions of parse graphs, simply as a matter of checking whether strings are well-formed formulas or not. Once this is done, there are many advantages to be gained from developing the graphical analogue of the calculus on strings. The mapping from strings to parse graphs is called  parsing  and the inverse mapping from parse graphs to strings is achieved by an operation that is called  traversing  the graph.       Propositional calculus is about the simplest kind of logical calculus in current use. It can be extended in several ways.  The most immediate way to develop a more complex logical calculus is to introduce rules that are sensitive to more fine-grained details of the sentences being used.      |First_order_logic|First_Order_Logic|  results when the atomic sentences of propositional logic are broken up into  |terms|Singular_Term| ,  |variables|Variable| ,  |predicates|Predicate| , and  |quantifiers|Quantifier| , all keeping the rules of propositional logic with some new ones introduced. With the tools of first-order logic it is possible to formulate a number of theories, either with explicit axioms or by rules of inference, that can themselves be treated as logical calculi.  |Arithmetic|Arithmetic|  is the best known of these; others include  |set_theory|Set_Theory|  and  |mereology|Mereology| .  |Second_order_logic|Second_Order_Logic|  and other  |higher_order_logics|Higher_Order_Logic|  are formal extensions of first-order logic. Thus, it makes sense to refer to propositional logic as  zeroth-order logic , when comparing it with these logics.      |Modal_logic|Modal_Logic|  also offers a variety of inferences that cannot be captured in propositional calculus. For example, from Necessarily  we may infer that . From  we may infer It is possible that  . The translation between modal logics and algebraic logics concerns classical and intuitionistic logics but with the introduction of a unary operator on Boolean or Heyting algebras, different from the Boolean operations, interpreting the possibility modality, and in the case of Heyting algebra a second operator interpreting necessity . The first operator preserves 0 and disjunction while the second preserves 1 and conjunction.      |Many_valued_logics|Many_Valued_Logic|  are those allowing sentences to have values other than true and false.  These logics often require calculational devices quite distinct from propositional calculus. When the values form a Boolean algebra , many-valued logic reduces to classical logic; many-valued logics are therefore only of independent interest when the values form an algebra that is not Boolean.       Finding solutions to propositional logic formulas is an  |NP_complete|Np_Complete|  problem. However, practical methods exist  that are very fast for many useful cases. Recent work has extended the  |SAT_solver|Sat_Solver|  algorithms to work with propositions containing  |arithmetic_expressions|Arithmetic_Expression| ; these are the  |SMT_solver|Smt_Solver| .