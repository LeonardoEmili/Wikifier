[
    {
        "   In ": null
    },
    {
        "computer science": "Computer Science"
    },
    {
        ", a sorting algorithm is an ": null
    },
    {
        "algorithm": "Algorithm"
    },
    {
        " that puts elements of a ": null
    },
    {
        "list": "List"
    },
    {
        " in a certain ": null
    },
    {
        "order": "Total Order"
    },
    {
        ". The most frequently used orders are ": null
    },
    {
        "numerical order": "Numerical Order"
    },
    {
        " and ": null
    },
    {
        "lexicographical order": "Lexicographical Order"
    },
    {
        ". Efficient ": null
    },
    {
        "sorting": "Sorting"
    },
    {
        " is important for optimizing the ": null
    },
    {
        "efficiency": "Algorithmic Efficiency"
    },
    {
        " of other algorithms  that require input data to be in sorted lists. Sorting is also often useful for ": null
    },
    {
        "canonicalizing": "Canonicalization"
    },
    {
        " data and for producing human-readable output. More formally, the output of any sorting algorithm must satisfy two conditions:     The output is in nondecreasing order ;   The output is a ": null
    },
    {
        "permutation": "Permutation"
    },
    {
        " of the input.     Further, the input data is often stored in an ": null
    },
    {
        "array": "Array Data Type"
    },
    {
        ", which allows ": null
    },
    {
        "random access": "Random Access"
    },
    {
        ", rather than a list, which only allows ": null
    },
    {
        "sequential access": "Sequential Access"
    },
    {
        "; though many algorithms can be applied to either type of data after suitable modification.     Sorting algorithms are often referred to as a word followed by the word sort, and grammatically are used in English as noun phrases, for example in the sentence, it is inefficient to use insertion sort on large lists, the phrase insertion sort refers to the ": null
    },
    {
        "insertion sort": "Insertion Sort"
    },
    {
        " sorting algorithm.       From the beginning of computing, the sorting problem has attracted a great deal of research, perhaps due to the complexity of solving it efficiently despite its simple, familiar statement. Among the authors of early sorting algorithms around 1951 was ": null
    },
    {
        "Betty Holberton": "Betty Holberton"
    },
    {
        " , who worked on ": null
    },
    {
        "ENIAC": "Eniac"
    },
    {
        " and ": null
    },
    {
        "UNIVAC": "Univac"
    },
    {
        ".   ": null
    },
    {
        "Bubble sort": "Bubble Sort"
    },
    {
        " was analyzed as early as 1956. Demuth, H. Electronic Data Sorting. PhD thesis, Stanford University, 1956. Comparison sorting algorithms have a fundamental requirement of ": null
    },
    {
        "Ω": "Big Omega Notation"
    },
    {
        " comparisons ; algorithms not based on comparisons, such as ": null
    },
    {
        "counting sort": "Counting Sort"
    },
    {
        ", can have better performance. Asymptotically optimal algorithms have been known since the mid-20th century  useful new algorithms are still being invented, with the now widely used ": null
    },
    {
        "Timsort": "Timsort"
    },
    {
        " dating to 2002, and the ": null
    },
    {
        "library sort": "Library Sort"
    },
    {
        " being first published in 2006.     Sorting algorithms are prevalent in introductory ": null
    },
    {
        "computer science": "Computer Science"
    },
    {
        " classes, where the abundance of algorithms for the problem provides a gentle introduction to a variety of core algorithm concepts, such as ": null
    },
    {
        "big O notation": "Big O Notation"
    },
    {
        ", ": null
    },
    {
        "divide and conquer algorithms": "Divide And Conquer Algorithm"
    },
    {
        ", ": null
    },
    {
        "data structures": "Data Structure"
    },
    {
        " such as ": null
    },
    {
        "heaps": "Heap"
    },
    {
        " and ": null
    },
    {
        "binary trees": "Binary Tree"
    },
    {
        ", ": null
    },
    {
        "randomized algorithms": "Randomized Algorithm"
    },
    {
        ", ": null
    },
    {
        "best, worst and average case": "Best, Worst And Average Case"
    },
    {
        " analysis, ": null
    },
    {
        "time–space tradeoffs": "Time–Space Tradeoff"
    },
    {
        ", and ": null
    },
    {
        "upper and lower bounds": "Upper And Lower Bounds"
    },
    {
        ".        Sorting algorithms are often classified by:     ": null
    },
    {
        "Computational complexity": "Computational Complexity Theory"
    },
    {
        "  in terms of the size of the list . For typical serial sorting algorithms good behavior is O, with parallel sort in O, and bad behavior is O.  Ideal behavior for a serial sort is O, but this is not possible in the average case. Optimal parallel sorting is O. ": null
    },
    {
        "Comparison-based sorting algorithms": "Comparison Sort"
    },
    {
        " need at least Ω comparisons for most inputs.   ": null
    },
    {
        "Computational complexity": "Computational Complexity Theory"
    },
    {
        " of swaps .   ": null
    },
    {
        "Memory": "Memory"
    },
    {
        " usage . In particular, some sorting algorithms are ": null
    },
    {
        "in-place": "In-Place Algorithm"
    },
    {
        " . Strictly, an in-place sort needs only O memory beyond the items being sorted; sometimes O additional memory is considered in-place .   Recursion. Some algorithms are either recursive or non-recursive, while others may be both .   Stability: ": null
    },
    {
        "stable sorting algorithms": "Stability"
    },
    {
        " maintain the relative order of records with equal keys .   Whether or not they are a ": null
    },
    {
        "comparison sort": "Comparison Sort"
    },
    {
        ". A comparison sort examines the data only by comparing two elements with a comparison operator.   General method: insertion, exchange, selection, merging, etc. Exchange sorts include bubble sort and quicksort. Selection sorts include shaker sort and heapsort.   Whether the algorithm is serial or parallel. The remainder of this discussion almost exclusively concentrates upon serial algorithms and assumes serial operation.   Adaptability: Whether or not the presortedness of the input affects the running time. Algorithms that take this into account are known to be ": null
    },
    {
        "adaptive": "Adaptive Sort"
    },
    {
        ".          Stable sort algorithms sort repeated elements in the same order that they appear in the input. When sorting some kinds of data, only part of the data is examined when determining the sort order. For example, in the card sorting example to the right, the cards are being sorted by their rank, and their suit is being ignored. This allows the possibility of multiple different correctly sorted versions of the original list. Stable sorting algorithms choose one of these, according to the following rule: if two items compare as equal, like the two 5 cards, then their relative order will be preserved, so that if one came before the other in the input, it will also come before the other in the output.     Stability is important for the following reason: say, if the data is sorted first by student name, in some cases, dynamically on the webpage, and now the data is again sorted by which class section they are in. Imagine for students that appear in the same section, the order of their names is shuffled up and not in any particular order, and this can be annoying. If a sorting algorithm is stable, the student names will still be in good order. A user might want to have the previous chosen sort orders preserved on the screen and a stable sort algorithm can do that. Another reason why stability is important: if the users are not programmers, then they can choose to sort by section and then by name, by first sorting using name and then sort again using section. If the sort algorithm is not stable, the users wont be able to do that.     More formally, the data being sorted can be represented as a record or tuple of values, and the part of the data that is used for sorting is called the key. In the card example, cards are represented as a record , and the key is the rank. A sorting algorithm is stable if whenever there are two records R and S with the same key, and R appears before S in the original list, then R will always appear before S in the sorted list.     When equal elements are indistinguishable, such as with integers, or more generally, any data where the entire element is the key, stability is not an issue. Stability is also not an issue if all keys are different.     Unstable sorting algorithms can be specially implemented to be stable. One way of doing this is to artificially extend the key comparison, so that comparisons between two objects with otherwise equal keys are decided using the order of the entries in the original input list as a tie-breaker. Remembering this order, however, may require additional time and space.     One application for stable sorting algorithms is sorting a list using a primary and secondary key. For example, suppose we wish to sort a hand of cards such that the suits are in the order clubs , diamonds , hearts , spades , and within each suit, the cards are sorted by rank. This can be done by first sorting the cards by rank , and then doing a stable sort by suit:          Within each suit, the stable sort preserves the ordering by rank that was already done. This idea can be extended to any number of keys and is utilised by ": null
    },
    {
        "radix sort": "Radix Sort"
    },
    {
        ". The same effect can be achieved with an unstable sort by using a lexicographic key comparison, which, e.g., compares first by suit, and then compares by rank if the suits are the same.       In this table,  is the number of records to be sorted. The columns Average and Worst give the ": null
    },
    {
        "time complexity": "Time Complexity"
    },
    {
        " in each case, under the assumption that the length of each key is constant, and that therefore all comparisons, swaps, and other needed operations can proceed in constant time. Memory denotes the amount of auxiliary storage needed beyond that used by the list itself, under the same assumption. The run times and the memory requirements listed below should be understood to be inside ": null
    },
    {
        "big O notation": "Big O Notation"
    },
    {
        ", hence the base of the logarithms does not matter; the notation  means .       Below is a table of ": null
    },
    {
        "comparison sorts": "Comparison Sort"
    },
    {
        ". A comparison sort cannot perform better than .      ": null
    }
]