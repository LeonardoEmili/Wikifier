             The design of experiments  is the design of any task that aims to describe and explain the variation of information under conditions that are hypothesized to reflect the variation. The term is generally associated with  |experiments|Experiments|  in which the design introduces conditions that directly affect the variation, but may also refer to the design of  |quasi_experiments|Quasi_Experiment| , in which  |natural|Naturalistic_Observation|  conditions that influence the variation are selected for observation.     In its simplest form, an experiment aims at predicting the outcome by introducing a change of the preconditions, which is represented by one or more  |independent_variables|Dependent_And_Independent_Variables| , also referred to as input variables or predictor variables. The change in one or more independent variables is generally hypothesized to result in a change in one or more  |dependent_variables|Dependent_And_Independent_Variables| , also referred to as output variables or response variables. The experimental design may also identify  |control_variables|Controlling_For_A_Variable|  that must be held constant to prevent external factors from affecting the results. Experimental design involves not only the selection of suitable independent, dependent, and control variables, but planning the delivery of the experiment under statistically optimal conditions given the constraints of available resources. There are multiple approaches for determining the set of design points to be used in the experiment.     Main concerns in experimental design include the establishment of  |validity|Validity| ,  |reliability|Reliability| , and  |replicability|Reproducibility| . For example, these concerns can be partially addressed by carefully choosing the independent variable, reducing the risk of measurement error, and ensuring that the documentation of the method is sufficiently detailed. Related concerns include achieving appropriate levels of  |statistical_power|Statistical_Power|  and  |sensitivity|Sensitivity_And_Specificity| .     Correctly designed experiments advance knowledge in the natural and social sciences and engineering. Other applications include marketing and policy making. The study of the design of experiments is an important topic in  |metascience|Metascience| .                 A theory of statistical inference was developed by  |Charles_S_Peirce|Charles_Sanders_Peirce|  in  |Illustrations_of_the_Logic_of_Science|Charles_Sanders_Peirce_Bibliographyillus|  and  |A_Theory_of_Probable_Inference|Charles_Sanders_Peirce_Bibliographysil|  , two publications that emphasized the importance of randomization-based inference in statistics.             Charles S. Peirce randomly assigned volunteers to a  |blinded|Blinding| ,  |repeated_measures_design|Repeated_Measures_Design|  to evaluate their ability to discriminate weights.             Peirces experiment inspired other researchers in psychology and education, which developed a research tradition of randomized experiments in laboratories and specialized textbooks in the 1800s.              |Charles_S_Peirce|Charles_Sanders_Peirce|  also contributed the first English-language publication on an  |optimal_design|Optimal_Design|  for  |regression|Regression_Analysis| |_models|Statistical_Model|  in 1876. , actually published 1879, NOAA . Reprinted in  Collected Papers  7, paragraphs 139–157, also in  Writings  4, pp. 72–78, and in  A pioneering  |optimal_design|Optimal_Design|  for  |polynomial_regression|Polynomial_Regression|  was suggested by  |Gergonne|Joseph_Diaz_Gergonne|  in 1815. In 1918,  |Kirstine_Smith|Kirstine_Smith|  published optimal designs for polynomials of degree six .             The use of a sequence of experiments, where the design of each may depend on the results of previous experiments, including the possible decision to stop experimenting, is within the scope of  |Sequential_analysis|Sequential_Analysis| , a field that was pioneered Johnson, N.L. . Sequential analysis: a survey.  Journal of the Royal Statistical Society , Series A. Vol. 124 , 372  411. by  |Abraham_Wald|Abraham_Wald|  in the context of sequential tests of statistical hypotheses. Wald, A. Sequential Tests of Statistical Hypotheses ,  |Annals_of_Mathematical_Statistics|Annals_Of_Mathematical_Statistics| , 16 , 117  186.  |Herman_Chernoff|Herman_Chernoff|  wrote an overview of optimal sequential designs, while  |adaptive_designs|Minimisation|  have been surveyed by S. Zacks. Zacks, S. Adaptive Designs for Parametric Models . In: Ghosh, S. and Rao, C. R., . Design and Analysis of Experiments, Handbook of Statistics, Volume 13. North-Holland. . One specific type of sequential design is the two-armed bandit , generalized to the  |multi_armed_bandit|Multi_Armed_Bandit| , on which early work was done by  |Herbert_Robbins|Herbert_Robbins|  in 1952.          A methodology for designing experiments was proposed by  |Ronald_Fisher|Ronald_Fisher| , in his innovative books: The Arrangement of Field Experiments and  The Design of Experiments  . Much of his pioneering work dealt with agricultural applications of statistical methods. As a mundane example, he described how to test the  |lady_tasting_tea|Lady_Tasting_Tea| |_hypothesis|Hypothesis| , that a certain lady could distinguish by flavour alone whether the milk or the tea was first placed in the cup. These methods have been broadly adapted in the physical and social sciences, are still used in  |agricultural_engineering|Agricultural_Engineering|  and differ from the design and analysis of  |computer_experiments|Computer_Experiment| .     ;Comparison   :In some fields of study it is not possible to have independent measurements to a traceable  |metrology_standard|Standard| . Comparisons between treatments are much more valuable and are usually preferable, and often compared against a  |scientific_control|Scientific_Control|  or traditional treatment that acts as baseline.     ; |Randomization|Randomization|    :Random assignment is the process of assigning individuals at random to groups or to different groups in an experiment, so that each individual of the population has the same chance of becoming a participant in the study. The random assignment of individuals to groups distinguishes a rigorous, true experiment from an observational study or quasi-experiment . Creswell, J.W. , Educational research: Planning, conducting, and evaluating quantitative and qualitative research , Upper Saddle River, NJ: Prentice Hall. 2008, p. 300.  There is an extensive body of mathematical theory that explores the consequences of making the allocation of units to treatments by means of some random mechanism . Assigning units to treatments at random tends to mitigate  |confounding|Confounding| , which makes effects due to factors other than the treatment to appear to result from the treatment.     :The risks associated with random allocation are calculable and hence can be managed down to an acceptable level by using enough experimental units. However, if the population is divided into several subpopulations that somehow differ, and the research requires each subpopulation to be equal in size, stratified sampling can be used. In that way, the units in each subpopulation are randomized, but not the whole sample. The results of an experiment can be generalized reliably from the experimental units to a larger  |statistical_population|Statistical_Population|  of units only if the experimental units are a  |random_sample|Sampling|  from the larger population; the probable error of such an extrapolation depends on the sample size, among other things.     ; |Statistical_replication|Replication|    :Measurements are usually subject to variation and  |measurement_uncertainty|Measurement_Uncertainty| ; thus they are repeated and full experiments are replicated to help identify the sources of variation, to better estimate the true effects of treatments, to further strengthen the experiments reliability and validity, and to add to the existing knowledge of the topic.  However, certain conditions must be met before the replication of the experiment is commenced: the original research question has been published in a  |peer_review|Peer_Review| ed journal or widely cited, the researcher is independent of the original experiment, the researcher must first try to replicate the original findings using the original data, and the write-up should state that the study conducted is a replication study that tried to follow the original study as strictly as possible.      ; |Blocking|Blocking|    :Blocking is the non-random arrangement of experimental units into groups consisting of units that are similar to one another. Blocking reduces known but irrelevant sources of variation between units and thus allows greater precision in the estimation of the source of variation under study.     ; |Orthogonality|Orthogonalitystatistics_2C_Econometrics_2C_And_Economics|       :Orthogonality concerns the forms of comparison that can be legitimately and efficiently carried out. Contrasts can be represented by vectors and sets of orthogonal contrasts are uncorrelated and independently distributed if the data are normal. Because of this independence, each orthogonal treatment provides different information to the others. If there are T treatments and T – 1 orthogonal contrasts, all the information that can be captured from the experiment is obtainable from the set of contrasts.     ; |Factorial_experiments|Factorial_Experiment|    :Use of factorial experiments instead of the one-factor-at-a-time method. These are efficient at evaluating the effects and possible  |interactions|Interaction|  of several factors . Analysis of  |experiment|Experiment|  design is built on the foundation of the  |analysis_of_variance|Analysis_Of_Variance| , a collection of models that partition the observed variance into components, according to what factors the experiment must estimate or test.          This example is attributed to  |Harold_Hotelling|Harold_Hotelling| .  |Herman_Chernoff|Herman_Chernoff| , Sequential Analysis and Optimal Design,  |SIAM|Society_For_Industrial_And_Applied_Mathematics|  Monograph, 1972. It conveys some of the flavor of those aspects of the subject that involve combinatorial designs.     Weights of eight objects are measured using a  |pan_balance|Pan_Balance|  and set of standard weights. Each weighing measures the weight difference between objects in the left pan and any objects in the right pan by adding calibrated weights to the lighter pan until the balance is in equilibrium. Each measurement has a  |random_error|Errors_And_Residuals_In_Statistics| . The average error is zero; the  |standard_deviations|Standard_Deviation|  of the  |probability_distribution|Probability_Distribution|  of the errors is the same number σ on different weighings; errors on different weighings are  |independent|Statistical_Independence| . Denote the true weights by     :           We consider two different experiments:     Weigh each object in one pan, with the other pan empty. Let X i be the measured weight of the object, for i 1, ..., 8.   Do the eight weighings according to the following schedule and let Y i be the measured difference for i 1, ..., 8:     ::       &   &             & 1  2  3  4  5  6  7  8 &         & 1  2  3  8  & 4  5  6  7       & 1  4  5  8  & 2  3  6  7       & 1  6  7  8  & 2  3  4  5       & 2  4  6  8  & 1  3  5  7       & 2  5  7  8  & 1  3  4  6       & 3  4  7  8  & 1  2  5  6       & 3  5  6  8  & 1  2  4  7           : Then the estimated value of the weight  & theta; 1 is     ::         :Similar estimates can be found for the weights of the other items. For example     ::         &   8.       &   8.       &   8.       &   8.       &   8.       &   8.       &   8.           The question of design of experiments is: which experiment is better?     The variance of the estimate X 1 of θ 1 is σ 2 if we use the first experiment. But if we use the second experiment, the variance of the estimate given above is σ 2 /8. Thus the second experiment gives us 8 times as much precision for the estimate of a single item, and estimates all items simultaneously, with the same precision. What the second experiment achieves with eight would require 64 weighings if the items are weighed separately. However, note that the estimates for the items obtained in the second experiment have errors that correlate with each other.     Many problems of the design of experiments involve  |combinatorial_designs|Combinatorial_Design| , as in this example and others.            |False_positive|False_Positive|  conclusions, often resulting from the  |pressure_to_publish|Publish_Or_Perish|  or the authors own  |confirmation_bias|Confirmation_Bias| , are an inherent hazard in many fields. A good way to prevent biases potentially leading to false positives in the data collection phase is to use a double-blind design. When a double-blind design is used, participants are randomly assigned to experimental groups but the researcher is unaware of what participants belong to which group. Therefore, the researcher can not affect the participants response to the intervention.   Experimental designs with undisclosed degrees of freedom are a problem.    This can lead to conscious or unconscious  |p_hacking|P_Hacking|  : trying multiple things until you get the desired result. It typically involves the manipulation - perhaps unconsciously - of the process of  |statistical_analysis|Statistical_Analysis|  and the degrees of freedom until they return a figure below the p  .