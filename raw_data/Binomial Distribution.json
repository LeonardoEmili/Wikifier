[
    {
        "            In ": null
    },
    {
        "probability theory": "Probability Theory"
    },
    {
        " and ": null
    },
    {
        "statistics": "Statistics"
    },
    {
        ", the binomial distribution with parameters n and p is the ": null
    },
    {
        "discrete probability distribution": "Discrete Probability Distribution"
    },
    {
        " of the number of successes in a sequence of n ": null
    },
    {
        "independent": "Statistical Independence"
    },
    {
        "experiments": "Experiment"
    },
    {
        ", each asking a ": null
    },
    {
        "yes–no question": "Yes–No Question"
    },
    {
        ", and each with its own ": null
    },
    {
        "boolean": "Boolean-Valued Function"
    },
    {
        "-valued ": null
    },
    {
        "outcome": "Outcome"
    },
    {
        "success": "Wikt:Success"
    },
    {
        "/": null
    },
    {
        "yes": "Yes And No"
    },
    {
        "/": null
    },
    {
        "true": "Truth Value"
    },
    {
        "/": null
    },
    {
        "one": "One"
    },
    {
        "  or ": null
    },
    {
        "failure": "Failure"
    },
    {
        "/": null
    },
    {
        "no": "Yes And No"
    },
    {
        "/": null
    },
    {
        "false": "False"
    },
    {
        "/": null
    },
    {
        "zero": "Zero"
    },
    {
        " .   A single success/failure experiment is also called a ": null
    },
    {
        "Bernoulli trial": "Bernoulli Trial"
    },
    {
        " or Bernoulli experiment and a sequence of outcomes is called a ": null
    },
    {
        "Bernoulli process": "Bernoulli Process"
    },
    {
        "; for a single trial, i.e., n    1, the binomial distribution is a ": null
    },
    {
        "Bernoulli distribution": "Bernoulli Distribution"
    },
    {
        ". The binomial distribution is the basis for the popular ": null
    },
    {
        "binomial test": "Binomial Test"
    },
    {
        " of ": null
    },
    {
        "statistical significance": "Statistical Significance"
    },
    {
        ".     The binomial distribution is frequently used to model the number of successes in a sample of size n drawn ": null
    },
    {
        "with replacement": "With Replacement"
    },
    {
        " from a population of size N. If the sampling is carried out without replacement, the draws are not independent and so the resulting distribution is a ": null
    },
    {
        "hypergeometric distribution": "Hypergeometric Distribution"
    },
    {
        ", not a binomial one. However, for N much larger than n, the binomial distribution remains a good approximation, and is widely used.             In general, if the ": null
    },
    {
        "random variable": "Random Variable"
    },
    {
        " X follows the binomial distribution with parameters n ": null
    },
    {
        "∈": "∈"
    },
    {
        " ℕ": "Natural Number"
    },
    {
        " and p ∈ we write X  ~  B. The probability of getting exactly k successes in n independent Bernoulli trials is given by the ": null
    },
    {
        "probability mass function": "Probability Mass Function"
    },
    {
        "k    0,  1,  2,  ...,  n, where     :         is the ": null
    },
    {
        "binomial coefficient": "Binomial Coefficient"
    },
    {
        ", hence the name of the distribution. The formula can be understood as follows. k successes occur with probability p k and n  −  k failures occur with probability  n  −  k . However, the k successes can occur anywhere among the n trials, and there are   different ways of distributing k successes in a sequence of n trials.     In creating reference tables for binomial distribution probability, usually the table is filled in up to n/2 values. This is because for k    math /math  math /math  ref  /ref math p.     f is monotone increasing for k     M, with the exception of the case where p is an integer. In this case, there are two values for which f is maximal: p and p  −  1. M is the most probable outcome of the Bernoulli trials and is called the ": null
    },
    {
        "mode": "Mode"
    },
    {
        ".         The ": null
    },
    {
        "cumulative distribution function": "Cumulative Distribution Function"
    },
    {
        " can be expressed as:     : F     pi     where   k  is the floor under k, i.e. the ": null
    },
    {
        "greatest integer": "Greatest Integer"
    },
    {
        " less than or equal to k.     It can also be represented in terms of the ": null
    },
    {
        "regularized incomplete beta function": "Regularized Incomplete Beta Function"
    },
    {
        ", as follows:      :     F &       & I     &   t k   dt.         which is equivalent to the ": null
    },
    {
        "cumulative distribution function": "Cumulative Distribution Function"
    },
    {
        " of the ": null
    },
    {
        "F-distribution": "F-Distribution"
    },
    {
        " Jowett G H , The Relationship Between the Binomial and F Distributions, Journal of the Royal Statistical Society D, 13, 55-57.     :   F F        Some closed-form bounds for the cumulative distribution function are given ": null
    },
    {
        "below": "Tail Bounds"
    },
    {
        ".         Suppose a ": null
    },
    {
        "biased coin": "Fair Coin"
    },
    {
        " comes up heads with probability 0.3 when tossed. What is the probability of achieving 0, 1,..., 6 heads after six tosses?     :   f   0.30 0.117649   :   f   0.31 0.302526   :   f   0.32 0.324135   :   f   0.33 0.18522   :   f   0.34 0.059535   :   f   0.35 0.010206   :   f   0.36 0.000729 Hamilton Institute.  October 20, 2010.           If X ~ B, that is, X is a binomially distributed random variable, n being the total number of experiments and p the probability of each experiment yielding a successful result, then the ": null
    },
    {
        "expected value": "Expected Value"
    },
    {
        " of X is: See      :   np.     This follows from the linearity of the expected value along with fact that  is the sum of  identical Bernoulli random variables, each with expected value . In other words, if X1,   Xn are identical Bernoulli random variables with parameter , then X X1 +   + Xn and   :       +   +   p +   + p np.     The ": null
    },
    {
        "variance": "Variance"
    },
    {
        " is:   :   np.     This similarly follows from the fact that the variance of a sum of independent random variables is the sum of the variances.       The first 6 central moments are given by   :       & 0,       & np,      & np,      & np,      & np,      & np.             Usually the ": null
    },
    {
        "mode": "Mode"
    },
    {
        " of a binomial B distribution is equal to   p  , where   is the ": null
    },
    {
        "floor function": "Floor Function"
    },
    {
        ". However, when p is an integer and p is neither 0 nor 1, then the distribution has two modes: p and p  −  1. When p is equal to 0 or 1, the mode will be 0 and n correspondingly. These cases can be summarized as follows:   :             &             - 1 &       n &   n + 1.         Proof: Let     : f  nk pk q.     For p0 only f has a nonzero value with f1 . For p1 we find f1 and f0 for k  n . This proves that the mode is 0 for p0 and n for p1 .     Let 0 n ": null
    }
]