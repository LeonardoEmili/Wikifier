            In  |probability_theory|Probability_Theory|  and  |statistics|Statistics| , the binomial distribution with parameters n and p is the  |discrete_probability_distribution|Discrete_Probability_Distribution|  of the number of successes in a sequence of n  |independent|Statistical_Independence| |experiments|Experiment| , each asking a  |yes–no_question|Yes–No_Question| , and each with its own  |boolean|Boolean_Valued_Function| -valued  |outcome|Outcome| |success|Wikt_Success| / |yes|Yes_And_No| / |true|Truth_Value| / |one|One|   or  |failure|Failure| / |no|Yes_And_No| / |false|False| / |zero|Zero|  .   A single success/failure experiment is also called a  |Bernoulli_trial|Bernoulli_Trial|  or Bernoulli experiment and a sequence of outcomes is called a  |Bernoulli_process|Bernoulli_Process| ; for a single trial, i.e., n    1, the binomial distribution is a  |Bernoulli_distribution|Bernoulli_Distribution| . The binomial distribution is the basis for the popular  |binomial_test|Binomial_Test|  of  |statistical_significance|Statistical_Significance| .     The binomial distribution is frequently used to model the number of successes in a sample of size n drawn  |with_replacement|With_Replacement|  from a population of size N. If the sampling is carried out without replacement, the draws are not independent and so the resulting distribution is a  |hypergeometric_distribution|Hypergeometric_Distribution| , not a binomial one. However, for N much larger than n, the binomial distribution remains a good approximation, and is widely used.             In general, if the  |random_variable|Random_Variable|  X follows the binomial distribution with parameters n  |∈|∈| |_ℕ|Natural_Number|  and p ∈ we write X  ~  B. The probability of getting exactly k successes in n independent Bernoulli trials is given by the  |probability_mass_function|Probability_Mass_Function| k    0,  1,  2,  ...,  n, where     :         is the  |binomial_coefficient|Binomial_Coefficient| , hence the name of the distribution. The formula can be understood as follows. k successes occur with probability p k and n  −  k failures occur with probability  n  −  k . However, the k successes can occur anywhere among the n trials, and there are   different ways of distributing k successes in a sequence of n trials.     In creating reference tables for binomial distribution probability, usually the table is filled in up to n/2 values. This is because for k    math /math  math /math  ref  /ref math p.     f is monotone increasing for k     M, with the exception of the case where p is an integer. In this case, there are two values for which f is maximal: p and p  −  1. M is the most probable outcome of the Bernoulli trials and is called the  |mode|Mode| .         The  |cumulative_distribution_function|Cumulative_Distribution_Function|  can be expressed as:     : F     pi     where   k  is the floor under k, i.e. the  |greatest_integer|Greatest_Integer|  less than or equal to k.     It can also be represented in terms of the  |regularized_incomplete_beta_function|Regularized_Incomplete_Beta_Function| , as follows:      :     F &       & I     &   t k   dt.         which is equivalent to the  |cumulative_distribution_function|Cumulative_Distribution_Function|  of the  |F_distribution|F_Distribution|  Jowett G H , The Relationship Between the Binomial and F Distributions, Journal of the Royal Statistical Society D, 13, 55-57.     :   F F        Some closed-form bounds for the cumulative distribution function are given  |below|Tail_Bounds| .         Suppose a  |biased_coin|Fair_Coin|  comes up heads with probability 0.3 when tossed. What is the probability of achieving 0, 1,..., 6 heads after six tosses?     :   f   0.30 0.117649   :   f   0.31 0.302526   :   f   0.32 0.324135   :   f   0.33 0.18522   :   f   0.34 0.059535   :   f   0.35 0.010206   :   f   0.36 0.000729 Hamilton Institute.  October 20, 2010.           If X ~ B, that is, X is a binomially distributed random variable, n being the total number of experiments and p the probability of each experiment yielding a successful result, then the  |expected_value|Expected_Value|  of X is: See      :   np.     This follows from the linearity of the expected value along with fact that  is the sum of  identical Bernoulli random variables, each with expected value . In other words, if X1,   Xn are identical Bernoulli random variables with parameter , then X X1 +   + Xn and   :       +   +   p +   + p np.     The  |variance|Variance|  is:   :   np.     This similarly follows from the fact that the variance of a sum of independent random variables is the sum of the variances.       The first 6 central moments are given by   :       & 0,       & np,      & np,      & np,      & np,      & np.             Usually the  |mode|Mode|  of a binomial B distribution is equal to   p  , where   is the  |floor_function|Floor_Function| . However, when p is an integer and p is neither 0 nor 1, then the distribution has two modes: p and p  −  1. When p is equal to 0 or 1, the mode will be 0 and n correspondingly. These cases can be summarized as follows:   :             &             - 1 &       n &   n + 1.         Proof: Let     : f  nk pk q.     For p0 only f has a nonzero value with f1 . For p1 we find f1 and f0 for k  n . This proves that the mode is 0 for p0 and n for p1 .     Let 0 n  .